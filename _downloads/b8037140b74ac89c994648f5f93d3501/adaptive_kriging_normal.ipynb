{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# U-Function & User-defined learning function\n\nIn this example, Monte Carlo Sampling is used to generate samples from Normal distribution and new samples are generated\nadaptively, using U-function as the learning criteria .\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Import the necessary libraries. Here we import standard libraries such as numpy, matplotlib and other necessary\nlibrary for plots, but also need to import the :class:`.MonteCarloSampling`,\n:class:`.AdaptiveKriging`, :class:`.Kriging` and :class:`.RunModel` class from UQpy.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import shutil\n\nfrom UQpy import PythonModel\nfrom UQpy.surrogates.gaussian_process import GaussianProcessRegression\nfrom UQpy.sampling import MonteCarloSampling, AdaptiveKriging\nfrom UQpy.run_model.RunModel import RunModel\nfrom UQpy.distributions import Normal\nfrom local_series import series\nimport matplotlib.pyplot as plt\nimport time\nfrom UQpy.utilities.MinimizeOptimizer import MinimizeOptimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Using UQpy :class:`.MonteCarloSampling` class to generate samples for two random variables, which are normally\ndistributed with mean $0$ and variance $1$.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "marginals = [Normal(loc=0., scale=4.), Normal(loc=0., scale=4.)]\nx = MonteCarloSampling(distributions=marginals, nsamples=20, random_state=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "RunModel class is used to define an object to evaluate the model at sample points.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model = PythonModel(model_script='local_series.py', model_object_name='series')\nrmodel = RunModel(model=model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":class:`.Kriging` class defines an object to generate a surrogate model for a given set of data.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from UQpy.surrogates.gaussian_process.regression_models import LinearRegression\nfrom UQpy.surrogates.gaussian_process.kernels import RBF\nbounds = [[10**(-3), 10**3], [10**(-3), 10**2], [10**(-3), 10**2]]\noptimizer = MinimizeOptimizer(method=\"L-BFGS-B\", bounds=bounds)\nK = GaussianProcessRegression(regression_model=LinearRegression(), kernel=RBF(), optimizer=optimizer,\n                              hyperparameters=[1, 1, 0.1], optimizations_number=10, noise=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This example works for all three learning function based on reliability analysis.\n\n:class:`.AdaptiveKriging` class is used to generate new sample using :class:`.UFunction` as active learning function.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from UQpy.sampling.adaptive_kriging_functions import *\nstart_time = time.time()\nlearning_function = WeightedUFunction(weighted_u_stop=2)\na = AdaptiveKriging(runmodel_object=rmodel, surrogate=K, learning_nsamples=10 ** 3, n_add=1,\n                    learning_function=learning_function, distributions=marginals, random_state=2)\na.run(nsamples=100, samples=x.samples)\n\nelapsed_time = time.time() - start_time\n\n\ntime.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time))\ng = a.surrogate.predict(a.learning_set, False)\nn_ = a.learning_set.shape[0] + len(a.qoi)\npf = (sum(g < 0) + sum(np.array(a.qoi) < 0)) / n_\nprint('Time: ', elapsed_time)\nprint('Function evaluation: ', a.samples.shape[0])\nprint('Probability of failure: ', pf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This figure shows the location of new samples generated using active learning function.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "num = 50\nx1 = np.linspace(-7, 7, num)\nx2 = np.linspace(-7, 7, num)\nx1v, x2v = np.meshgrid(x1, x2)\ny = np.zeros([num, num])\ny_act = np.zeros([num, num])\nmse = np.zeros([num, num])\nfor i in range(num):\n    for j in range(num):\n        xa = marginals[0].cdf(np.atleast_2d(x1v[i, j]))\n        ya = marginals[1].cdf(np.atleast_2d(x2v[i, j]))\n        y[i, j] = a.surrogate.predict(np.hstack([xa, ya]))\n        y_act[i, j] = series(np.array([[x1v[i, j], x2v[i, j]]]))\n\nfig, ax = plt.subplots()\nkr_a = ax.contour(x1v, x2v, y_act, levels=[0], colors='Black')\n\n# Plot for scattered data\nnd = x.nsamples\nID1 = ax.scatter(a.samples[nd:, 0], a.samples[nd:, 1], color='Grey', label='New samples')\nID = ax.scatter(x.samples[:nd, 0], x.samples[:nd, 1], color='Red', label='Initial samples')\nplt.legend(handles=[ID1, ID])\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## User-defined Learning function\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class UserLearningFunction(LearningFunction):\n\n    def __init__(self, u_stop: int = 2):\n        self.u_stop = u_stop\n\n    def evaluate_function(self, distributions, n_add, surrogate, population, qoi=None, samples=None):\n        # AKMS class use these inputs to compute the learning function\n\n        g, sig = surrogate.predict(population, True)\n\n        # Remove the inconsistency in the shape of 'g' and 'sig' array\n        g = g.reshape([population.shape[0], 1])\n        sig = sig.reshape([population.shape[0], 1])\n\n        u = abs(g) / sig\n        rows = u[:, 0].argsort()[:n_add]\n\n        indicator = False\n        if min(u[:, 0]) >= self.u_stop:\n            indicator = True\n\n        return population[rows, :], u[rows, 0], indicator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Creating new instances of :class:`.Kriging` and :class:`.RunModel` class.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "bounds = [[10**(-3), 10**3], [10**(-3), 10**2], [10**(-3), 10**2]]\noptimizer = MinimizeOptimizer(method=\"L-BFGS-B\", bounds=bounds)\nK1 = GaussianProcessRegression(regression_model=LinearRegression(), kernel=RBF(), optimizer=optimizer,\n                               hyperparameters=[1, 1, 0.1], optimizations_number=1)\nmodel = PythonModel(model_script='local_series.py', model_object_name='series')\nrmodel1 = RunModel(model=model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Executing :class:`Adaptivekriging` with the user-defined learning function.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "start_time = time.time()\nak = AdaptiveKriging(runmodel_object=rmodel1, samples=x.samples, surrogate=K1, learning_nsamples=10 ** 3,\n                     n_add=1, learning_function=UserLearningFunction(), distributions=marginals, random_state=3)\nak.run(nsamples=100)\n\n\nelapsed_time = time.time() - start_time\n\ntime.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time))\ng = ak.surrogate.predict(ak.learning_set, False)\nn_ = ak.learning_set.shape[0] + len(ak.qoi)\npf = (sum(g < 0) + sum(np.array(ak.qoi) < 0)) / n_\nprint('Time: ', elapsed_time)\nprint('Function evaluation: ', ak.samples.shape[0])\nprint('Probability of failure: ', pf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This figure shows the location of new samples generated using active learning function.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig1, ax1 = plt.subplots()\nkr_a = ax1.contour(x1v, x2v, y_act, levels=[0], colors='Black')\n\n# Plot for scattered data\nID1 = ax1.scatter(ak.samples[nd:, 0], ak.samples[nd:, 1], color='Grey', label='New samples')\nID = ax1.scatter(x.samples[:nd, 0], x.samples[:nd, 1], color='Red', label='Initial samples')\nplt.legend(handles=[ID1, ID])\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Monte Carlo Simulation\nProbability of failure and covariance is estimated using Monte Carlo Simulation. 10,000 samples are generated\nrandomly using :class:`.MonteCarloSampling` class and model is evaluated at all samples.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "start_time = time.time()\n\n# Code\nb = MonteCarloSampling(distributions=marginals, nsamples=10 ** 4, random_state=4)\nmodel = PythonModel(model_script='local_series.py', model_object_name='series')\nr1model = RunModel(model=model)\nr1model.run(samples=b.samples)\n\n\ngx = np.array(r1model.qoi_list)\npf_mcs = np.sum(np.array(gx) < 0) / b.nsamples\ncov_pf_mcs = np.sqrt((1 - pf_mcs) / (pf_mcs * b.nsamples))\nelapsed_time = time.time() - start_time\ntime.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Results from Monte Carlo Simulation.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print('Time: ', elapsed_time)\nprint('Function evaluation: ', b.nsamples)\nprint('Probability of failure: ', pf_mcs)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}