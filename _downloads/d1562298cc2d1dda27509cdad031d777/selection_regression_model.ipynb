{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# 2. Selection between regression models\n\nHere candidate models are defined as\n\n\\begin{align}y=f(\u03b8) + \\epsilon\\end{align}\n\nwhere $f$ consists in running RunModel. The three models considered are:\n\n\\begin{align}f(\u03b8)=\u03b8_{0} x\\end{align}\n\n\\begin{align}f(\u03b8)=\u03b8_{0} x + \u03b8_{1} x^{2}\\end{align}\n\n\\begin{align}f(\u03b8)=\u03b8_{0} x + \u03b8_{1} x^{2} + \u03b8_{2} x^{3}\\end{align}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Initially we have to import the necessary modules.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import shutil\n\nfrom UQpy import PythonModel\nfrom UQpy.inference import InformationModelSelection, MLE\nfrom UQpy.run_model.RunModel import RunModel\nimport numpy as np\nfrom UQpy.inference import BIC\nimport matplotlib.pyplot as plt\nfrom UQpy.distributions import Normal\nfrom UQpy.inference import ComputationalModel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First we generate synthetic data using the quadratic model, and add some noise to it.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "param_true = np.array([1.0, 2.0]).reshape((1, -1))\nprint('Shape of true parameter vector: {}'.format(param_true.shape))\n\nmodel = PythonModel(model_script='pfn_models.py', model_object_name='model_quadratic', var_names=['theta_0', 'theta_1'])\nh_func = RunModel(model=model)\nh_func.run(samples=param_true)\n\n# Add noise\nerror_covariance = 1.\ndata_clean = np.array(h_func.qoi_list[0])\nnoise = Normal(loc=0., scale=np.sqrt(error_covariance)).rvs(nsamples=50).reshape((50,))\ndata_1 = data_clean + noise\nprint('Shape of data: {}'.format(data_1.shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create instances of the Model class for three models: linear, quadratic and cubic\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "names = ['model_linear', 'model_quadratic', 'model_cubic']\nestimators = []\n\nfor i in range(3):\n    model = PythonModel(model_script='pfn_models.py', model_object_name=names[i],\n                        var_names=['theta_{}'.format(j) for j in range(i + 1)])\n    h_func = RunModel(model=model)\n    M = ComputationalModel(runmodel_object=h_func, n_parameters=i + 1,\n                           name=names[i], error_covariance=error_covariance)\n    estimators.append(MLE(inference_model=M, data=data_1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Apart from the data, candidate models and method (:class:`.BIC`, :class:`.AIC`...),\n:class:`.InformationModelSelection` also takes as inputs lists of\ninputs to the maximum likelihood class. Those inputs should be lists of length\nlen(candidate_models).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from UQpy.utilities.MinimizeOptimizer import MinimizeOptimizer\noptimizer = MinimizeOptimizer(method='nelder-mead')\nselector = InformationModelSelection(parameter_estimators=estimators, criterion=BIC(), n_optimizations=[1]*3)\nselector.sort_models()\nprint('Sorted models: ', [m.name for m in selector.candidate_models])\nprint('Values of criterion: ', selector.criterion_values)\nprint('Values of data fit:', [cr - pe for (cr, pe) in zip(selector.criterion_values, selector.penalty_terms)])\nprint('Values of penalty term (complexity):', selector.penalty_terms)\nprint('Values of model probabilities:', selector.probabilities)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot the results\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "domain = np.linspace(0, 10, 50)\nfig, ax = plt.subplots(figsize=(8, 6))\n\nfor i, (model, estim) in enumerate(zip(selector.candidate_models, selector.parameter_estimators)):\n    model.runmodel_object.run(samples=estim.mle.reshape((1, -1)), append_samples=False)\n    y = model.runmodel_object.qoi_list[-1].reshape((-1,))\n    ax.plot(domain, y, label=selector.candidate_models[i].name)\n\nplt.plot(domain, data_1, linestyle='none', marker='.', label='data')\nplt.xlabel('x')\nplt.ylabel('y')\n\nplt.legend()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For this case, one can observe that both the quadratic and cubic model are capable of explaining the data. The cubic\nmodel is penalized due to its higher complexity (penalty_term) and thus the quadratic model is preferred.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}