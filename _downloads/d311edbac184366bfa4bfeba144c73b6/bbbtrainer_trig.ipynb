{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Training with Variational Inference\n\nIn this example, we train a Bayesian neural network using Variational Inference.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First, we import the necessary modules and, optionally, set UQpy to print logs to the console.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import logging\nimport numpy as np\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nimport matplotlib.pyplot as plt\nimport UQpy.scientific_machine_learning as sml\n\n# logger = logging.getLogger(\"UQpy\")  # Optional, display UQpy logs to console\n# logger.setLevel(logging.INFO)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Our neural network will approximate the function $f(x)=0.4 \\sin(4x) + 0.5 \\cos(12x) + \\epsilon$ over the domain\n$x \\in [-1, 1]$. $\\epsilon$ represents the noise in our measurement defined as the Gaussian random\nvariable $\\epsilon \\sim N(0, 0.05)$.\n\nBelow we define the dataset by subclassing :py:class:`torch.utils.data.Dataset`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class SinusoidalDataset(Dataset):\n    def __init__(self, n_samples=20, noise_std=0.05):\n        self.n_samples = n_samples\n        self.noise_std = noise_std\n        self.x = torch.linspace(-1, 1, n_samples).reshape(-1, 1)\n        self.y = torch.tensor(\n            0.4 * np.sin(4 * self.x)\n            + 0.5 * np.cos(12 * self.x)\n            + np.random.normal(0, self.noise_std, self.x.shape),\n            dtype=torch.float,\n        )\n\n    def __len__(self):\n        return self.n_samples\n\n    def __getitem__(self, item):\n        return self.x[item], self.y[item]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, we define our model architecture using UQpy's :py:class:`BayesianLinear` layers and train the model.\nThe model is trained using the Bayes-by-backprop implementation in :py:class:`BBBTrainer`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "width = 20\nnetwork = nn.Sequential(\n    sml.BayesianLinear(1, width),\n    nn.ReLU(),\n    sml.BayesianLinear(width, width),\n    nn.ReLU(),\n    sml.BayesianLinear(width, width),\n    nn.ReLU(),\n    sml.BayesianLinear(width, width),\n    nn.ReLU(),\n    sml.BayesianLinear(width, 1),\n)\nmodel = sml.FeedForwardNeuralNetwork(network)\n\ndataset = SinusoidalDataset()\ntrain_data = DataLoader(dataset, batch_size=20, shuffle=True)\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\ntrainer = sml.BBBTrainer(model, optimizer)\nprint(\"Starting Training...\", end=\"\")\ntrainer.run(train_data=train_data, epochs=5_000, beta=1e-6, num_samples=10)\nprint(\"done\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "That's the hard part done! We defined our dataset, our model, and then fit the model to the data.\nThe rest of this example plots the model predictions to compare them to the exact solution.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Plot training history\nfig, ax = plt.subplots()\nax.semilogy(trainer.history[\"train_loss\"])\nax.set_title(\"Bayes By Backpropagation Training Loss\")\nax.set(xlabel=\"Epoch\", ylabel=\"Loss\")\n\n# Plot model predictions\nx_noisy = dataset.x\ny_noisy = dataset.y\nx_exact = torch.linspace(-1, 1, 1000).reshape(-1, 1)\ny_exact = 0.4 * torch.sin(4 * x_exact) + 0.5 * torch.cos(12 * x_exact)\n\n# compute mean prediction from model\nmodel.eval()\nmodel.sample(False)\nprint(\"BNN is deterministic:\", model.is_deterministic())\nwith torch.no_grad():\n    mean_prediction = model(x_exact)\n\n# compute stochastic prediction from model\nmodel.sample(True)\nprint(\"BNN is deterministic:\", model.is_deterministic())\nn = 1_000\nsamples = torch.zeros(len(x_exact), n)\nwith torch.no_grad():\n    for i in range(n):\n        samples[:, i] = model(x_exact).squeeze()\nstandard_deviation = torch.std(samples, dim=1)\n\n# convert tensors to numpy arrays for matplotlib\nx_exact = x_exact.squeeze().detach().numpy()\ny_exact = y_exact.squeeze().detach().numpy()\nmean_prediction = mean_prediction.squeeze().detach().numpy()\nstandard_deviation = standard_deviation.squeeze().detach().numpy()\n\nfig, ax = plt.subplots()\nax.scatter(x_noisy, y_noisy, label=\"Training Data\", color=\"black\")\nax.plot(\n    x_exact,\n    y_exact,\n    label=\"Exact\",\n    color=\"black\",\n    linestyle=\"dashed\",\n)\nax.plot(x_exact, mean_prediction, label=\"Model $\\mu$\", color=\"tab:blue\")\nax.fill_between(\n    x_exact,\n    mean_prediction - (3 * standard_deviation),\n    mean_prediction + (3 * standard_deviation),\n    label=\"$\\mu \\pm 3\\sigma$,\",\n    color=\"tab:blue\",\n    alpha=0.3,\n)\nax.set_title(\"Bayesian Neural Network Predictions\")\nax.set(xlabel=\"x\", ylabel=\"f(x)\")\nax.legend()\n\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}