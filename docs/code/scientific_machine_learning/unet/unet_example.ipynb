{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3f8872",
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "Imports"
   },
   "outputs": [],
   "source": [
    "# Imports \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import UQpy.scientific_machine_learning as sml\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from mpl_toolkits import axes_grid1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5dddcae",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Check if GPU is available and set the device accordingly\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Using CUDA (NVIDIA GPU)\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"Using MPS (Apple Silicon GPU)\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU\")\n",
    "\n",
    "print(f\"Selected device: {device}\")\n",
    "\n",
    "# Colorbar function\n",
    "def add_colorbar(im, aspect=20, pad_fraction=0.5, **kwargs):\n",
    "    divider = axes_grid1.make_axes_locatable(im.axes)\n",
    "    width = axes_grid1.axes_size.AxesY(im.axes, aspect=1. / aspect)\n",
    "    pad = axes_grid1.axes_size.Fraction(pad_fraction, width)\n",
    "    cax = divider.append_axes(\"right\", size=width, pad=pad)\n",
    "    return im.axes.figure.colorbar(im, cax=cax, **kwargs)\n",
    "\n",
    "# Visualization of data\n",
    "def plot_images(X, Y, title, num_samples):\n",
    "    fig, axes = plt.subplots(num_samples, 2, figsize=(10, num_samples * 5))\n",
    "    fig.suptitle(title, fontsize=16)\n",
    "    plt.ion()\n",
    "    for i in range(num_samples):\n",
    "        # Adjusted for transposed shape\n",
    "        axes[i, 0].imshow(X[i, 0], cmap='viridis')\n",
    "        axes[i, 0].set_title(f\"Input microstructure {i + 1}\")\n",
    "        axes[i, 0].axis('off')\n",
    "\n",
    "        im = axes[i, 1].imshow(Y[i, 0], cmap='viridis')\n",
    "        add_colorbar(im)\n",
    "        axes[i, 1].set_title(\"Ground Truth Mask\")\n",
    "        axes[i, 1].axis('off')\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    plt.show()\n",
    "    plt.ioff()\n",
    "\n",
    "## % Define dataset with appropriate shape\n",
    "class FiberDataset(Dataset):\n",
    "    def __init__(self, X, Y, num_samples=None, img_size=None):\n",
    "        self.X = np.transpose(X, (3, 2, 0, 1))  # Transpose to (N, C_in, H, W)\n",
    "        self.Y = np.transpose(Y, (3, 2, 0, 1))  # Transpose to (N, C_out, H, W)\n",
    "        # Select only one channel, keep dimensions\n",
    "        self.X = self.X[:, :1, :, :]\n",
    "        self.Y = self.Y[:, :1, :, :]\n",
    "\n",
    "        if num_samples is not None:\n",
    "            self.X = self.X[:num_samples]\n",
    "            self.Y = self.Y[:num_samples]\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.X[idx], dtype=torch.float32), torch.tensor(self.Y[idx], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297ceff2",
   "metadata": {
    "title": "Load data and define trainers"
   },
   "outputs": [],
   "source": [
    "X_tr = np.load('./data/X_tr.npy')\n",
    "Y_tr = np.load('./data/Y_tr.npy')\n",
    "X_val = np.load('./data/X_val.npy')\n",
    "Y_val = np.load('./data/Y_val.npy')\n",
    "\n",
    "train_dataset = FiberDataset(X_tr, Y_tr)\n",
    "val_dataset = FiberDataset(X_val, Y_val)\n",
    "\n",
    "plot_images(train_dataset.X, train_dataset.Y, \"Training Set Examples\", 3)\n",
    "plot_images(val_dataset.X, val_dataset.Y, \"Validation Set Examples\", 3)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046cfeae",
   "metadata": {
    "title": "Define U-Net model"
   },
   "outputs": [],
   "source": [
    "n_filters = [1, 16, 32, 64, 128]\n",
    "kernel_size = 3\n",
    "out_channels = 1\n",
    "unet = sml.Unet(n_filters, kernel_size, out_channels).to(device)\n",
    "\n",
    "# Set up optimizer and scheduler\n",
    "optimizer = torch.optim.Adam(unet.parameters(), lr=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=0.005)\n",
    "\n",
    "# Set up Trainer and train\n",
    "trainer = sml.Trainer(unet, optimizer, scheduler=scheduler)\n",
    "print(\"Starting Training...\")\n",
    "trainer.run(train_data=train_loader, test_data=val_loader,\n",
    "            epochs=1000)  \n",
    "print(\"Training Complete.\")\n",
    "\n",
    "# Save model weights and plot\n",
    "fig_dir = 'figures'\n",
    "os.makedirs(fig_dir, exist_ok=True)\n",
    "weights_path = os.path.join(fig_dir, 'unet_weights.pth')\n",
    "torch.save(unet.state_dict(), weights_path)\n",
    "print(f\"Model weights saved to {weights_path}\")\n",
    "\n",
    "# Plot training history\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(trainer.history[\"train_loss\"], label=\"Train Loss\")\n",
    "ax.plot(trainer.history[\"test_loss\"], label=\"Validation Loss\")\n",
    "ax.set_title(\"Training and Validation Loss\")\n",
    "ax.set(xlabel=\"Epoch\", ylabel=\"Loss\")\n",
    "ax.legend()\n",
    "fig_path = os.path.join(fig_dir, 'training_validation_loss.png')\n",
    "fig.savefig(fig_path)\n",
    "print(f\"Figure saved to {fig_path}\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "title,-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
