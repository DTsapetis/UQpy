

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Polynomial Chaos Expansion example: Active Learning for Multiple Surrogate Models &mdash; UQpy v4.1.7 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../../../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../../../_static/sg_gallery.css?v=d2d258e8" />
      <link rel="stylesheet" type="text/css" href="../../../_static/sg_gallery-binder.css?v=f4aeca0c" />
      <link rel="stylesheet" type="text/css" href="../../../_static/sg_gallery-dataframe.css?v=2082cf3c" />
      <link rel="stylesheet" type="text/css" href="../../../_static/sg_gallery-rendered-html.css?v=1277b6f3" />

  
      <script src="../../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../../_static/documentation_options.js?v=72eccc5f"></script>
      <script src="../../../_static/doctools.js?v=9bcbadda"></script>
      <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="MCMC" href="../../../sampling/mcmc/index.html" />
    <link rel="prev" title="Theta Criterion PCE Examples" href="index.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search"  style="background: #F0F0F0" >

          
          
          <a href="../../../index.html">
            
              <img src="../../../_static/logo.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../../index.html">Home</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../dimension_reduction/index.html">Dimension Reduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../distributions/index.html">Distributions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../inference/index.html">Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../reliability/index.html">Reliability</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../runmodel_doc.html">RunModel</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../../../sampling/index.html">Sampling</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../../../sampling/monte_carlo.html"> Monte Carlo Sampling</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../sampling/latin_hypercube.html"> Latin Hypercube Sampling</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../sampling/stratified_sampling.html"> True Stratified Sampling</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../sampling/refined_stratified_sampling.html"> Refined Stratified Sampling</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../sampling/simplex.html"> Simplex Sampling</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../sampling/akmcs.html"> Adaptive Kriging</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../../../sampling/theta_criterion.html"> Theta Criterion</a><ul class="current">
<li class="toctree-l3 current"><a class="reference internal" href="../../../sampling/theta_criterion.html#thetacriterionpce-class">ThetaCriterionPCE Class</a><ul class="current">
<li class="toctree-l4"><a class="reference internal" href="../../../sampling/theta_criterion.html#methods">Methods</a></li>
<li class="toctree-l4 current"><a class="reference internal" href="../../../sampling/theta_criterion.html#examples">Examples</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../sampling/mcmc/index.html"> Markov Chain Monte Carlo</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../sampling/importance_sampling.html"> Importance Sampling</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../scientific_machine_learning/index.html">Scientific Machine Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../sensitivity/index.html">Sensitivity</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../stochastic_process/index.html">Stochastic Process</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../surrogates/index.html">Surrogates</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../transformations/index.html">Transformations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../utilities/index.html">Utilities</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../architecture.html">UQpy architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../paper.html">UQpy paper</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../bibliography.html">Bibliography</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../news_doc.html">News</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu"  style="background: #F0F0F0" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">UQpy</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../../../sampling/index.html">Sampling</a></li>
          <li class="breadcrumb-item"><a href="../../../sampling/theta_criterion.html">Theta Criterion</a></li>
          <li class="breadcrumb-item"><a href="index.html">Theta Criterion PCE Examples</a></li>
      <li class="breadcrumb-item active">Polynomial Chaos Expansion example: Active Learning for Multiple Surrogate Models</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../../_sources/auto_examples/sampling/theta_criterion/pce_theta_criterion.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p><a class="reference internal" href="#sphx-glr-download-auto-examples-sampling-theta-criterion-pce-theta-criterion-py"><span class="std std-ref">Go to the end</span></a>
to download the full example code. or to run this example in your browser via Binder</p>
</div>
<section class="sphx-glr-example-title" id="polynomial-chaos-expansion-example-active-learning-for-multiple-surrogate-models">
<span id="sphx-glr-auto-examples-sampling-theta-criterion-pce-theta-criterion-py"></span><h1>Polynomial Chaos Expansion example: Active Learning for Multiple Surrogate Models<a class="headerlink" href="#polynomial-chaos-expansion-example-active-learning-for-multiple-surrogate-models" title="Link to this heading"></a></h1>
<p>In this example, we use active learning for construction of optimal experimental design with respect to exploration of
the design domain and exploitation of given surrogate models in form of Polynomial Chaos Expansion (PCE). Active learning is based on <span class="math notranslate nohighlight">\(\Theta\)</span> criterion recently proposed in</p>
<ol class="upperalpha simple" start="12">
<li><p>Novák, M. Vořechovský, V. Sadílek, M. D. Shields, <em>Variance-based adaptive sequential sampling for polynomial chaos expansion</em>, 637 Computer Methods in Applied Mechanics and Engineering 386 (2021) 114105. doi:10.1016/j.cma.2021.114105.</p></li>
</ol>
<p>We start with the necessary imports.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">UQpy.sampling.ThetaCriterionPCE</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">UQpy.distributions</span><span class="w"> </span><span class="kn">import</span> <span class="n">Uniform</span><span class="p">,</span> <span class="n">JointIndependent</span><span class="p">,</span> <span class="n">Normal</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">UQpy.surrogates</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">UQpy.sampling</span><span class="w"> </span><span class="kn">import</span> <span class="n">LatinHypercubeSampling</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">UQpy.sampling.stratified_sampling.latin_hypercube_criteria</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span>
</pre></div>
</div>
<p>The example involves a <span class="math notranslate nohighlight">\(2D\)</span> function with mirrored quarter-circle arc line singularities. The form of the function is give by:</p>
<div class="math notranslate nohighlight">
\[f(\mathbf{X})=  \frac{1}{ \lvert 0.3-X_1^2 - X_2^2\rvert + \delta}- \frac{1}{ \lvert 0.3-(1-X_1)^2 - (1-X_2)^2\rvert + \delta}, \quad \mathbf{X} \sim \mathcal{U}[0,1]^2\]</div>
<p>where the strength of the singularities is controlled by the parameter <span class="math notranslate nohighlight">\(\delta\)</span>, which we set as <span class="math notranslate nohighlight">\(\delta=0.01\)</span>.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">Model2DComplete</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">delta</span><span class="o">=</span><span class="mf">0.01</span><span class="p">):</span>
    <span class="n">Y</span> <span class="o">=</span> <span class="n">Model2D1</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="o">+</span> <span class="n">Model2D2</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">Y</span>
</pre></div>
</div>
<p>In order to show the possibilities of active learning for multiple surrogate models, we split the function into the two parts as follows:</p>
<div class="math notranslate nohighlight">
\[\begin{split}f_1(\mathbf{X})= \begin{cases} \frac{1}{ \lvert 0.3-X_1^2 - X_2^2\rvert + \delta}-\frac{1}{ \lvert 0.3-(1-X_1)^2 - (1-X_2)^2\rvert + \delta} \quad \text{for} \quad X_1&lt;X_2\\ 0 \quad \text{otherwise} \end{cases}\end{split}\]</div>
<p>and</p>
<div class="math notranslate nohighlight">
\[\begin{split}f_2(\mathbf{X})= \begin{cases} \frac{1}{ \lvert 0.3-X_1^2 - X_2^2\rvert + \delta}-\frac{1}{ \lvert 0.3-(1-X_1)^2 - (1-X_2)^2\rvert + \delta} \quad \text{for} \quad X_1&gt;X_2\\ 0 \quad \text{otherwise} \end{cases}\end{split}\]</div>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">Model2D1</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">delta</span><span class="o">=</span><span class="mf">0.01</span><span class="p">):</span>
    <span class="n">M</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span>
    <span class="n">Y</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="mf">0.3</span> <span class="o">-</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">-</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="n">delta</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span>
                <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="mf">0.3</span> <span class="o">-</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">])</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">-</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="n">delta</span><span class="p">)</span>
    <span class="n">Y</span><span class="p">[</span><span class="n">M</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">return</span> <span class="n">Y</span>


<span class="k">def</span><span class="w"> </span><span class="nf">Model2D2</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">delta</span><span class="o">=</span><span class="mf">0.01</span><span class="p">):</span>
    <span class="n">M</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span>
    <span class="n">Y</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="mf">0.3</span> <span class="o">-</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">-</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="n">delta</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span>
                <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="mf">0.3</span> <span class="o">-</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">])</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">-</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="n">delta</span><span class="p">)</span>
    <span class="n">Y</span><span class="p">[</span><span class="n">M</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">return</span> <span class="n">Y</span>
</pre></div>
</div>
<p>The mathematical models have independent random inputs, which are uniformly distributed in interval <span class="math notranslate nohighlight">\([0, 1]\)</span>.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="c1"># input distributions</span>
<span class="n">dist1</span> <span class="o">=</span> <span class="n">Uniform</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">dist2</span> <span class="o">=</span> <span class="n">Uniform</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">marg</span> <span class="o">=</span> <span class="p">[</span><span class="n">dist1</span><span class="p">,</span> <span class="n">dist2</span><span class="p">]</span>
<span class="n">joint</span> <span class="o">=</span> <span class="n">JointIndependent</span><span class="p">(</span><span class="n">marginals</span><span class="o">=</span><span class="n">marg</span><span class="p">)</span>
</pre></div>
</div>
<p>We must now select a polynomial basis. Here we opt for a total-degree (TD) basis, such that the univariate polynomials have a maximum degree equal to <span class="math notranslate nohighlight">\(P\)</span> and all multivariate polynomial have a total-degree (sum of degrees of corresponding univariate polynomials) at most equal to <span class="math notranslate nohighlight">\(P\)</span>. The size of the basis is then given by</p>
<div class="math notranslate nohighlight">
\[\frac{(N+P)!}{N! P!}\]</div>
<p>where <span class="math notranslate nohighlight">\(N\)</span> is the number of random inputs (here, <span class="math notranslate nohighlight">\(N=2\)</span>).</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="c1"># realizations of random inputs</span>
<span class="c1"># training data</span>
<span class="c1"># maximum polynomial degree</span>
<span class="n">P</span> <span class="o">=</span> <span class="mi">10</span>
<span class="c1"># construct total-degree polynomial basis and use OLS for estimation of coefficients</span>
<span class="n">polynomial_basis</span> <span class="o">=</span> <span class="n">TotalDegreeBasis</span><span class="p">(</span><span class="n">joint</span><span class="p">,</span> <span class="n">P</span><span class="p">)</span>
</pre></div>
</div>
<p>We must now compute the PCE coefficients. For that we first need a training sample of input random variable realizations and the corresponding model outputs. These two data sets form what is also known as an ‘’experimental design’’. In case of adaptive construction of PCE by the best model selection algorithm, size of ED is given apriori and the most suitable basis functions are adaptively selected. Here we have two surrogate models with identical training samples of input random vector and two sets of corresponding mathematical models. This ED represents small initial ED, which will be further extended by active learning algorithm.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="c1"># number of inital traning samples</span>
<span class="n">sample_size</span> <span class="o">=</span> <span class="mi">15</span>

<span class="c1"># realizations of input random vector</span>
<span class="n">xx_train</span> <span class="o">=</span> <span class="n">joint</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">sample_size</span><span class="p">)</span>

<span class="c1"># corresponding model outputs</span>
<span class="n">yy_train1</span> <span class="o">=</span> <span class="n">Model2D1</span><span class="p">(</span><span class="n">xx_train</span><span class="p">)</span>
<span class="n">yy_train2</span> <span class="o">=</span> <span class="n">Model2D2</span><span class="p">(</span><span class="n">xx_train</span><span class="p">)</span>
</pre></div>
</div>
<p>We now fit the PCE coefficients by solving a regression problem. Here we opt for the <code class="code docutils literal notranslate"><span class="pre">np.linalg.lstsq</span></code> method, which is based on the _dgelsd_ solver of LAPACK. This original PCE class will be used for further selection of the best basis functions. Once we have created the PCE containing all basis functions generated by TD algorithm, it is possible to reduce the number of basis functions by LAR algorithm. We create sparse PCE approximations for both mathematical models as follows.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">least_squares</span> <span class="o">=</span> <span class="n">LeastSquareRegression</span><span class="p">()</span>

<span class="c1"># fit model 1</span>
<span class="n">pce1</span> <span class="o">=</span> <span class="n">PolynomialChaosExpansion</span><span class="p">(</span><span class="n">polynomial_basis</span><span class="o">=</span><span class="n">polynomial_basis</span><span class="p">,</span> <span class="n">regression_method</span><span class="o">=</span><span class="n">least_squares</span><span class="p">)</span>
<span class="n">pce1</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">xx_train</span><span class="p">,</span> <span class="n">yy_train1</span><span class="p">)</span>
<span class="n">pceLAR1</span> <span class="o">=</span> <span class="n">polynomial_chaos</span><span class="o">.</span><span class="n">regressions</span><span class="o">.</span><span class="n">LeastAngleRegression</span><span class="o">.</span><span class="n">model_selection</span><span class="p">(</span><span class="n">pce1</span><span class="p">)</span>

<span class="c1"># fit model 2</span>
<span class="n">pce2</span> <span class="o">=</span> <span class="n">PolynomialChaosExpansion</span><span class="p">(</span><span class="n">polynomial_basis</span><span class="o">=</span><span class="n">polynomial_basis</span><span class="p">,</span> <span class="n">regression_method</span><span class="o">=</span><span class="n">least_squares</span><span class="p">)</span>
<span class="n">pce2</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">xx_train</span><span class="p">,</span> <span class="n">yy_train2</span><span class="p">)</span>
<span class="n">pceLAR2</span> <span class="o">=</span> <span class="n">polynomial_chaos</span><span class="o">.</span><span class="n">regressions</span><span class="o">.</span><span class="n">LeastAngleRegression</span><span class="o">.</span><span class="n">model_selection</span><span class="p">(</span><span class="n">pce2</span><span class="p">)</span>
</pre></div>
</div>
<p>The active learning algorithm based on $Theta$ criterion selects the best sample from given large set of candidates coverign uniformly the whole design domain. Here we set number of samples as <span class="math notranslate nohighlight">\(n_{cand}=10^4\)</span> and use LHS-MaxiMin for sampling, though any sampling technique can be employed.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="c1"># number of candidates for the active learning algorithm</span>
<span class="n">n_cand</span> <span class="o">=</span> <span class="mi">10000</span>

<span class="c1"># MaxiMin LHS samples uniformly covering the whole input random space</span>
<span class="n">lhs_maximin_cand</span> <span class="o">=</span> <span class="n">LatinHypercubeSampling</span><span class="p">(</span><span class="n">distributions</span><span class="o">=</span><span class="p">[</span><span class="n">dist1</span><span class="p">,</span> <span class="n">dist2</span><span class="p">],</span>
                                          <span class="n">criterion</span><span class="o">=</span><span class="n">MaxiMin</span><span class="p">(</span><span class="n">metric</span><span class="o">=</span><span class="n">DistanceMetric</span><span class="o">.</span><span class="n">CHEBYSHEV</span><span class="p">),</span>
                                          <span class="n">nsamples</span><span class="o">=</span><span class="n">n_cand</span><span class="p">)</span>

<span class="c1"># candidates for active learning</span>
<span class="n">Xaptive</span> <span class="o">=</span> <span class="n">lhs_maximin_cand</span><span class="o">.</span><span class="n">_samples</span>
</pre></div>
</div>
<p>Start of the active learning algorithm interatively selecting <span class="math notranslate nohighlight">\(nsamples=400\)</span> samples one-by-one. Note that the class <code class="code docutils literal notranslate"><span class="pre">ThetaCriterionPCE</span></code> takes a list of surrogate models as input, here we have 2 PCEs approximated 2 mathematical models. The active learning further selects the best candidate in each run by variance-based <span class="math notranslate nohighlight">\(\Theta\)</span> criterion.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="c1"># total number of added points by the active learning algorithm</span>
<span class="n">naddedsims</span> <span class="o">=</span> <span class="mi">400</span>

<span class="c1"># loading of existing ED for both PCEs</span>
<span class="n">Xadapted</span> <span class="o">=</span> <span class="n">xx_train</span>
<span class="n">Yadapted1</span> <span class="o">=</span> <span class="n">yy_train1</span>
<span class="n">Yadapted2</span> <span class="o">=</span> <span class="n">yy_train2</span>

<span class="c1"># adaptive algorithm and reconstruction of PCE</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">naddedsims</span><span class="p">)):</span>
    <span class="c1"># create ThetaCriterion class for active learning</span>
    <span class="n">ThetaSampling</span> <span class="o">=</span> <span class="n">ThetaCriterionPCE</span><span class="p">([</span><span class="n">pceLAR1</span><span class="p">,</span> <span class="n">pceLAR2</span><span class="p">])</span>

    <span class="c1"># find the best candidate according to given criterium (variance and distance)</span>
    <span class="n">pos</span> <span class="o">=</span> <span class="n">ThetaSampling</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">Xadapted</span><span class="p">,</span> <span class="n">Xaptive</span><span class="p">)</span>
    <span class="n">newpointX</span> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array" title="numpy.array" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">array</span></a><span class="p">([</span><span class="n">Xaptive</span><span class="p">[</span><span class="n">pos</span><span class="p">,</span> <span class="p">:]])</span>

    <span class="n">newpointres1</span> <span class="o">=</span> <span class="n">Model2D1</span><span class="p">(</span><span class="n">newpointX</span><span class="p">)</span>
    <span class="n">newpointres2</span> <span class="o">=</span> <span class="n">Model2D2</span><span class="p">(</span><span class="n">newpointX</span><span class="p">)</span>

    <span class="c1"># add the best candidate to experimental design</span>
    <span class="n">Xadapted</span> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.append.html#numpy.append" title="numpy.append" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">append</span></a><span class="p">(</span><span class="n">Xadapted</span><span class="p">,</span> <span class="n">newpointX</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">Yadapted1</span> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.r_.html#numpy.r_" title="numpy.r_" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-data"><span class="n">np</span><span class="o">.</span><span class="n">r_</span></a><span class="p">[</span><span class="n">Yadapted1</span><span class="p">,</span> <span class="n">newpointres1</span><span class="p">]</span>
    <span class="n">Yadapted2</span> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.r_.html#numpy.r_" title="numpy.r_" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-data"><span class="n">np</span><span class="o">.</span><span class="n">r_</span></a><span class="p">[</span><span class="n">Yadapted2</span><span class="p">,</span> <span class="n">newpointres2</span><span class="p">]</span>

    <span class="c1"># reconstruct the PCE 1</span>
    <span class="n">pce1</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xadapted</span><span class="p">,</span> <span class="n">Yadapted1</span><span class="p">)</span>
    <span class="n">pceLAR1</span> <span class="o">=</span> <span class="n">polynomial_chaos</span><span class="o">.</span><span class="n">regressions</span><span class="o">.</span><span class="n">LeastAngleRegression</span><span class="o">.</span><span class="n">model_selection</span><span class="p">(</span><span class="n">pce1</span><span class="p">)</span>

    <span class="c1"># reconstruct the PCE 2</span>
    <span class="n">pce2</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xadapted</span><span class="p">,</span> <span class="n">Yadapted2</span><span class="p">)</span>
    <span class="n">pceLAR2</span> <span class="o">=</span> <span class="n">polynomial_chaos</span><span class="o">.</span><span class="n">regressions</span><span class="o">.</span><span class="n">LeastAngleRegression</span><span class="o">.</span><span class="n">model_selection</span><span class="p">(</span><span class="n">pce2</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="mi">10</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Number of added simulations:&#39;</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>

<span class="c1"># plot final ED</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax_nstd</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">ax_nstd</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">Xadapted</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">Xadapted</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="s1">&#39;ro&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Adapted ED&#39;</span><span class="p">)</span>
<span class="n">ax_nstd</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xx_train</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">xx_train</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="s1">&#39;bo&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Original ED&#39;</span><span class="p">)</span>
<span class="n">ax_nstd</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$X_2$&#39;</span><span class="p">)</span>
<span class="n">ax_nstd</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$X_1$&#39;</span><span class="p">)</span>
<span class="n">ax_nstd</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper left&#39;</span><span class="p">);</span>
</pre></div>
</div>
<p>For a comparison, we construct also a surrogate model of the full original mathematical model and further run active learning similarly as for the previous reduced models. Note that the final ED for this complete mathematical model should be almost identical as in the previous case with the two PCEs approximating reduced models.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">yy_train3</span> <span class="o">=</span> <span class="n">Model2DComplete</span><span class="p">(</span><span class="n">xx_train</span><span class="p">)</span>
<span class="n">pce3</span> <span class="o">=</span> <span class="n">PolynomialChaosExpansion</span><span class="p">(</span><span class="n">polynomial_basis</span><span class="o">=</span><span class="n">polynomial_basis</span><span class="p">,</span> <span class="n">regression_method</span><span class="o">=</span><span class="n">least_squares</span><span class="p">)</span>
<span class="n">pce3</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">xx_train</span><span class="p">,</span> <span class="n">yy_train3</span><span class="p">)</span>
<span class="n">pceLAR3</span> <span class="o">=</span> <span class="n">polynomial_chaos</span><span class="o">.</span><span class="n">regressions</span><span class="o">.</span><span class="n">LeastAngleRegression</span><span class="o">.</span><span class="n">model_selection</span><span class="p">(</span><span class="n">pce3</span><span class="p">)</span>



<span class="n">Xadapted3</span> <span class="o">=</span> <span class="n">xx_train</span>
<span class="n">Yadapted3</span> <span class="o">=</span> <span class="n">yy_train3</span>

<span class="c1"># adaptive algorithm and reconstruction of PCE</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="mi">400</span><span class="p">)):</span>
    <span class="c1"># create ThetaCriterion class for active learning</span>
    <span class="n">ThetaSampling_complete</span> <span class="o">=</span> <span class="n">ThetaCriterionPCE</span><span class="p">([</span><span class="n">pceLAR3</span><span class="p">])</span>

    <span class="c1"># find the best candidate according to given criterium (variance and distance)</span>
    <span class="n">pos</span> <span class="o">=</span> <span class="n">ThetaSampling_complete</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">Xadapted3</span><span class="p">,</span> <span class="n">Xaptive</span><span class="p">)</span>
    <span class="n">newpointX</span> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array" title="numpy.array" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">array</span></a><span class="p">([</span><span class="n">Xaptive</span><span class="p">[</span><span class="n">pos</span><span class="p">,</span> <span class="p">:]])</span>
    <span class="n">newpointres</span> <span class="o">=</span> <span class="n">Model2DComplete</span><span class="p">(</span><span class="n">newpointX</span><span class="p">)</span>

    <span class="c1"># add the best candidate to experimental design</span>
    <span class="n">Xadapted3</span> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.append.html#numpy.append" title="numpy.append" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-function"><span class="n">np</span><span class="o">.</span><span class="n">append</span></a><span class="p">(</span><span class="n">Xadapted3</span><span class="p">,</span> <span class="n">newpointX</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">Yadapted3</span> <span class="o">=</span> <a href="https://numpy.org/doc/stable/reference/generated/numpy.r_.html#numpy.r_" title="numpy.r_" class="sphx-glr-backref-module-numpy sphx-glr-backref-type-py-data"><span class="n">np</span><span class="o">.</span><span class="n">r_</span></a><span class="p">[</span><span class="n">Yadapted3</span><span class="p">,</span> <span class="n">newpointres</span><span class="p">]</span>

    <span class="n">pce3</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">Xadapted3</span><span class="p">,</span> <span class="n">Yadapted3</span><span class="p">)</span>
    <span class="n">pceLAR3</span> <span class="o">=</span> <span class="n">polynomial_chaos</span><span class="o">.</span><span class="n">regressions</span><span class="o">.</span><span class="n">LeastAngleRegression</span><span class="o">.</span><span class="n">model_selection</span><span class="p">(</span><span class="n">pce3</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="mi">10</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Number of added simulations:&#39;</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>

<span class="c1"># plot final ED</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax_nstd</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">ax_nstd</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">Xadapted3</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">Xadapted3</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="s1">&#39;ro&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Adapted ED&#39;</span><span class="p">)</span>
<span class="n">ax_nstd</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xx_train</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">xx_train</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="s1">&#39;bo&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Original ED&#39;</span><span class="p">)</span>
<span class="n">ax_nstd</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$X_2$&#39;</span><span class="p">)</span>
<span class="n">ax_nstd</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$X_1$&#39;</span><span class="p">)</span>
<span class="n">ax_nstd</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper left&#39;</span><span class="p">);</span>
</pre></div>
</div>
<div class="sphx-glr-footer sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-examples-sampling-theta-criterion-pce-theta-criterion-py">
<div class="binder-badge docutils container">
<a class="reference external image-reference" href="https://mybinder.org/v2/gh/SURGroup/UQpy/master?urlpath=lab/tree/notebooks/auto_examples/sampling/theta_criterion/pce_theta_criterion.ipynb"><img alt="Launch binder" src="../../../_images/binder_badge_logo24.svg" style="width: 150px;" />
</a>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../../../_downloads/451832d998d04af6b0d611eeca919f42/pce_theta_criterion.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">pce_theta_criterion.ipynb</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../../../_downloads/f317de8ab2bf080496f242f5f8732048/pce_theta_criterion.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">pce_theta_criterion.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-zip docutils container">
<p><a class="reference download internal" download="" href="../../../_downloads/cc5318bd4a88c8fffb2ea6691b55a1c2/pce_theta_criterion.zip"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">zipped:</span> <span class="pre">pce_theta_criterion.zip</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="index.html" class="btn btn-neutral float-left" title="Theta Criterion PCE Examples" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../../../sampling/mcmc/index.html" class="btn btn-neutral float-right" title="MCMC" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021, Michael D. Shields.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>