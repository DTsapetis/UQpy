

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Bayesian Quickstart Training &mdash; UQpy v4.1.7 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../../../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../../../_static/sg_gallery.css?v=d2d258e8" />
      <link rel="stylesheet" type="text/css" href="../../../_static/sg_gallery-binder.css?v=f4aeca0c" />
      <link rel="stylesheet" type="text/css" href="../../../_static/sg_gallery-dataframe.css?v=2082cf3c" />
      <link rel="stylesheet" type="text/css" href="../../../_static/sg_gallery-rendered-html.css?v=1277b6f3" />

  
      <script src="../../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../../_static/documentation_options.js?v=72eccc5f"></script>
      <script src="../../../_static/doctools.js?v=9bcbadda"></script>
      <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="Bayesian Quickstart Testing" href="bayesian_quickstart_testing.html" />
    <link rel="prev" title="Scientific Machine Learning" href="../../../scientific_machine_learning/index.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search"  style="background: #F0F0F0" >

          
          
          <a href="../../../index.html">
            
              <img src="../../../_static/logo.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../../index.html">Home</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../dimension_reduction/index.html">Dimension Reduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../distributions/index.html">Distributions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../inference/index.html">Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../reliability/index.html">Reliability</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../runmodel_doc.html">RunModel</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../sampling/index.html">Sampling</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../../../scientific_machine_learning/index.html">Scientific Machine Learning</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="../../../scientific_machine_learning/index.html#quickstart">Quickstart</a><ul class="current">
<li class="toctree-l3 current"><a class="current reference internal" href="#"> Bayesian Quickstart Training</a></li>
<li class="toctree-l3"><a class="reference internal" href="bayesian_quickstart_testing.html"> Bayesian Quickstart Testing</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../scientific_machine_learning/index.html#functional">Functional</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../scientific_machine_learning/index.html#layers">Layers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../scientific_machine_learning/index.html#losses">Losses</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../scientific_machine_learning/index.html#neural-networks">Neural Networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../scientific_machine_learning/index.html#trainers">Trainers</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../sensitivity/index.html">Sensitivity</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../stochastic_process/index.html">Stochastic Process</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../surrogates/index.html">Surrogates</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../transformations/index.html">Transformations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../utilities/index.html">Utilities</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../architecture.html">UQpy architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../paper.html">UQpy paper</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../bibliography.html">Bibliography</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../news_doc.html">News</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu"  style="background: #F0F0F0" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">UQpy</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../../../scientific_machine_learning/index.html">Scientific Machine Learning</a></li>
      <li class="breadcrumb-item active">Bayesian Quickstart Training</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../../_sources/auto_examples/scientific_machine_learning/bayesian_quickstart/bayesian_quickstart_training.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p><a class="reference internal" href="#sphx-glr-download-auto-examples-scientific-machine-learning-bayesian-quickstart-bayesian-quickstart-training-py"><span class="std std-ref">Go to the end</span></a>
to download the full example code. or to run this example in your browser via Binder</p>
</div>
<section class="sphx-glr-example-title" id="bayesian-quickstart-training">
<span id="sphx-glr-auto-examples-scientific-machine-learning-bayesian-quickstart-bayesian-quickstart-training-py"></span><h1>Bayesian Quickstart Training<a class="headerlink" href="#bayesian-quickstart-training" title="Link to this heading"></a></h1>
<p>This is the first half of a Bayesian version of the classification problem from this Pytorch Quickstart tutorial:
(<a class="reference external" href="https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html">https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html</a>)</p>
<p>We strongly recommend reading the Pytorch quick start first to familiarize yourself with the problem.
We include many of the comments from the Pytorch example, but assume the reader is familiar with model definitions
and parameter optimization in Pytorch.
In their tutorial, Pytorch implements a fully connected deterministic neural network to learn a classification of
articles of clothing. Here, we implement a fully connected <em>Bayesian</em> neural network to learn the same classification.</p>
<p>We import all the same packages, with the addition of UQpy’s scientific machine learning module.
Note that this demo requires the <code class="docutils literal notranslate"><span class="pre">torchvision</span></code> package.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch</span><span class="w"> </span><span class="kn">import</span> <span class="n">nn</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchvision</span><span class="w"> </span><span class="kn">import</span> <span class="n">datasets</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torchvision.transforms</span><span class="w"> </span><span class="kn">import</span> <span class="n">ToTensor</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">UQpy.scientific_machine_learning</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">sml</span>
</pre></div>
</div>
<p>The FashionMNIST dataset <span id="id1">[<a class="reference internal" href="../../../bibliography.html#id72" title="Han Xiao, Kashif Rasul, and Roland Vollgraf. Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms. 2017. arXiv:cs.LG/1708.07747.">36</a>]</span> and dataloaders for our Bayesian classifier are identical to those used in the
deterministic case.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Download training data from open datasets.</span>
<span class="n">training_data</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">FashionMNIST</span><span class="p">(</span>
    <span class="n">root</span><span class="o">=</span><span class="s2">&quot;data&quot;</span><span class="p">,</span>
    <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">transform</span><span class="o">=</span><span class="n">ToTensor</span><span class="p">(),</span>
<span class="p">)</span>

<span class="c1"># Download test data from open datasets.</span>
<span class="n">test_data</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">FashionMNIST</span><span class="p">(</span>
    <span class="n">root</span><span class="o">=</span><span class="s2">&quot;data&quot;</span><span class="p">,</span>
    <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">transform</span><span class="o">=</span><span class="n">ToTensor</span><span class="p">(),</span>
<span class="p">)</span>

<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">64</span>
<span class="c1"># Create data loaders.</span>
<span class="n">train_dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">training_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>
<span class="n">test_dataloader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">test_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>

<span class="k">for</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">test_dataloader</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Shape of X [N, C, H, W]: </span><span class="si">{</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Shape of y: </span><span class="si">{</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">y</span><span class="o">.</span><span class="n">dtype</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">break</span>
</pre></div>
</div>
<p>To construct a Bayesian classifier, we use UQpy’s <code class="docutils literal notranslate"><span class="pre">BayesianLinear</span></code> layers in the <code class="docutils literal notranslate"><span class="pre">nn.Module</span></code> subclass.
The <code class="docutils literal notranslate"><span class="pre">BayesianLinear</span></code> takes in the in features and out features just like <code class="docutils literal notranslate"><span class="pre">nn.Linear</span></code>.
The key difference is while the standard Linear layer has deterministic numbers for every element in its weight
and bias tensors, a BayesianLinear layer has a representation of a random variable for each element in its tensors.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Get cpu, gpu or mps device for training.</span>
<span class="n">device</span> <span class="o">=</span> <span class="s2">&quot;cpu&quot;</span>
<span class="c1"># device = (</span>
<span class="c1">#     &quot;cuda&quot;</span>
<span class="c1">#     if torch.cuda.is_available()</span>
<span class="c1">#     else &quot;mps&quot; if torch.backends.mps.is_available() else &quot;cpu&quot;</span>
<span class="c1"># )</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Using </span><span class="si">{</span><span class="n">device</span><span class="si">}</span><span class="s2"> device&quot;</span><span class="p">)</span>


<span class="c1"># Define model</span>
<span class="k">class</span><span class="w"> </span><span class="nc">BayesianNeuralNetwork</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;UQpy: Replace torch&#39;s nn.Linear with UQpy&#39;s sml.BayesianLinear&quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">flatten</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear_relu_stack</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">sml</span><span class="o">.</span><span class="n">BayesianLinear</span><span class="p">(</span><span class="mi">28</span> <span class="o">*</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">512</span><span class="p">),</span>  <span class="c1"># nn.Linear(28 * 28, 512)</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">sml</span><span class="o">.</span><span class="n">BayesianLinear</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">512</span><span class="p">),</span>  <span class="c1"># nn.Linear(512, 512)</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">sml</span><span class="o">.</span><span class="n">BayesianLinear</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">512</span><span class="p">),</span>  <span class="c1"># nn.Linear(512, 512)</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
            <span class="n">sml</span><span class="o">.</span><span class="n">BayesianLinear</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span>  <span class="c1"># nn.Linear(512, 10)</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear_relu_stack</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">logits</span>
</pre></div>
</div>
<p>Just like in Torch tutorials, we define our network using an instance of this custom class.
The network is wrapped inside the <code class="docutils literal notranslate"><span class="pre">sml.FeedForwardNeuralNetwork</span></code> object, which does not change the network but gives
us better control over the random variable behavior. By default, the model is set to sampling mode, where the weights
and biases of each Bayesian layer are sampled from their governing distribution. We can turn sampling off,
which causes the model to use the means of its distributions (and consequently behave deterministically) with the
command <code class="docutils literal notranslate"><span class="pre">model.sample(False)</span></code>. To turn sampling back on, use <code class="docutils literal notranslate"><span class="pre">model.sample(True)</span></code>.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">network</span> <span class="o">=</span> <span class="n">BayesianNeuralNetwork</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">sml</span><span class="o">.</span><span class="n">FeedForwardNeuralNetwork</span><span class="p">(</span><span class="n">network</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;model is in sampling mode:&quot;</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">sampling</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;model is in sampling mode:&quot;</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">sampling</span><span class="p">)</span>
</pre></div>
</div>
<p>With our model defined, we can turn our attention to training. Training a Bayesian neural network uses Torch’s
<code class="docutils literal notranslate"><span class="pre">optim</span></code> library, and we can reuse almost all of their training and testing functions.
We use the testing function from torch’s quickstart tutorial, with a small modification to the loss function.
We add a divergence term to the loss, which represents the likelihood of the posterior distribution in the Bayesian
update. The default prior distribution in a Bayesian layer is a zero mean Gaussian, so this effectively acts as a
regularization term driving the weights and biases towards zero. We scale down the divergence by a factor of
<span class="math notranslate nohighlight">\(10^{-6}\)</span> so it doesn’t dominate the total loss.</p>
<p>The test function is nearly identical to torch’s, with the inclusion of a single line to ensure the
sampling mode is set to <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">loss_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="c1"># UQpy: define divergence function used in loss</span>
<span class="n">divergence_fn</span> <span class="o">=</span> <span class="n">sml</span><span class="o">.</span><span class="n">GaussianKullbackLeiblerDivergence</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">train</span><span class="p">(</span><span class="n">dataloader</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">loss_fn</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;UQpy: Include a divergence term in the loss&quot;&quot;&quot;</span>
    <span class="n">size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataloader</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
    <span class="c1"># UQpy: Set to sample mode to True.</span>
    <span class="n">model</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">batch</span><span class="p">,</span> <span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dataloader</span><span class="p">):</span>
        <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

        <span class="c1"># Compute prediction error</span>
        <span class="n">pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

        <span class="c1"># UQpy: Compute divergence and add it to the data loss</span>
        <span class="n">beta</span> <span class="o">=</span> <span class="mf">1e-6</span>
        <span class="n">loss</span> <span class="o">+=</span> <span class="n">beta</span> <span class="o">*</span> <span class="n">divergence_fn</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>

        <span class="c1"># Backpropagation</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">batch</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">loss</span><span class="p">,</span> <span class="n">current</span> <span class="o">=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="p">(</span><span class="n">batch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;loss: </span><span class="si">{</span><span class="n">loss</span><span class="si">:</span><span class="s2">&gt;7f</span><span class="si">}</span><span class="s2">  [</span><span class="si">{</span><span class="n">current</span><span class="si">:</span><span class="s2">&gt;5d</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">size</span><span class="si">:</span><span class="s2">&gt;5d</span><span class="si">}</span><span class="s2">]&quot;</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">test</span><span class="p">(</span><span class="n">dataloader</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">loss_fn</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;UQpy: ensure model sampling is turned off.&quot;&quot;&quot;</span>
    <span class="n">size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataloader</span><span class="o">.</span><span class="n">dataset</span><span class="p">)</span>
    <span class="n">num_batches</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataloader</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="c1"># UQpy: Set sampling mode to False</span>
    <span class="n">model</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">test_loss</span><span class="p">,</span> <span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="k">for</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">dataloader</span><span class="p">:</span>
            <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="n">pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
            <span class="n">test_loss</span> <span class="o">+=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
            <span class="n">correct</span> <span class="o">+=</span> <span class="p">(</span><span class="n">pred</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
    <span class="n">test_loss</span> <span class="o">/=</span> <span class="n">num_batches</span>
    <span class="n">correct</span> <span class="o">/=</span> <span class="n">size</span>
    <span class="nb">print</span><span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot;Test Error: </span><span class="se">\n</span><span class="s2"> Accuracy: </span><span class="si">{</span><span class="p">(</span><span class="mi">100</span><span class="o">*</span><span class="n">correct</span><span class="p">)</span><span class="si">:</span><span class="s2">&gt;0.1f</span><span class="si">}</span><span class="s2">%, Avg loss: </span><span class="si">{</span><span class="n">test_loss</span><span class="si">:</span><span class="s2">&gt;8f</span><span class="si">}</span><span class="s2"> </span><span class="se">\n</span><span class="s2">&quot;</span>
    <span class="p">)</span>


<span class="n">epochs</span> <span class="o">=</span> <span class="mi">5</span>
<span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Epoch </span><span class="si">{</span><span class="n">t</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="se">\n</span><span class="s2">-------------------------------&quot;</span><span class="p">)</span>
    <span class="n">train</span><span class="p">(</span><span class="n">train_dataloader</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">loss_fn</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">)</span>
    <span class="n">test</span><span class="p">(</span><span class="n">test_dataloader</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">loss_fn</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Done!&quot;</span><span class="p">)</span>

<span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="s2">&quot;bayesian_model.pt&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Saved PyTorch Model State to bayesian_model.pt&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>That’s it! We defined the Bayesian neural network using UQpy’s layers and added the model divergence to the loss
function. That’s the basics of defining and training a Bayesian neural network.</p>
<p>In the next tutorial we make predictions with this trained Bayesian model.</p>
<div class="sphx-glr-footer sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-examples-scientific-machine-learning-bayesian-quickstart-bayesian-quickstart-training-py">
<div class="binder-badge docutils container">
<a class="reference external image-reference" href="https://mybinder.org/v2/gh/SURGroup/UQpy/master?urlpath=lab/tree/notebooks/auto_examples/scientific_machine_learning/bayesian_quickstart/bayesian_quickstart_training.ipynb"><img alt="Launch binder" src="../../../_images/binder_badge_logo26.svg" style="width: 150px;" />
</a>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../../../_downloads/e2a7f59782a641ed3ab3e6528b518cb7/bayesian_quickstart_training.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">bayesian_quickstart_training.ipynb</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../../../_downloads/5a256bd1b3336e3275a731f4f7d7ef2a/bayesian_quickstart_training.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">bayesian_quickstart_training.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-zip docutils container">
<p><a class="reference download internal" download="" href="../../../_downloads/45b34b2b71a1d985ec1847d48a4cc3f8/bayesian_quickstart_training.zip"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">zipped:</span> <span class="pre">bayesian_quickstart_training.zip</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="../../../scientific_machine_learning/index.html" class="btn btn-neutral float-left" title="Scientific Machine Learning" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="bayesian_quickstart_testing.html" class="btn btn-neutral float-right" title="Bayesian Quickstart Testing" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021, Michael D. Shields.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>