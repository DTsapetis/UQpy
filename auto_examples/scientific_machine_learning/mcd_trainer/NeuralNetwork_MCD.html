

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Probabilisitc Models with Monte Carlo Dropout &mdash; UQpy v4.1.7 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../../../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../../../_static/sg_gallery.css?v=d2d258e8" />
      <link rel="stylesheet" type="text/css" href="../../../_static/sg_gallery-binder.css?v=f4aeca0c" />
      <link rel="stylesheet" type="text/css" href="../../../_static/sg_gallery-dataframe.css?v=2082cf3c" />
      <link rel="stylesheet" type="text/css" href="../../../_static/sg_gallery-rendered-html.css?v=1277b6f3" />

  
      <script src="../../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../../_static/documentation_options.js?v=72eccc5f"></script>
      <script src="../../../_static/doctools.js?v=9bcbadda"></script>
      <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="List of Fourier Layers" href="../../../scientific_machine_learning/layers/fourier_layers.html" />
    <link rel="prev" title="Monte Carlo Dropout Examples" href="index.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search"  style="background: #F0F0F0" >

          
          
          <a href="../../../index.html">
            
              <img src="../../../_static/logo.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../../index.html">Home</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../dimension_reduction/index.html">Dimension Reduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../distributions/index.html">Distributions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../inference/index.html">Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../reliability/index.html">Reliability</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../runmodel_doc.html">RunModel</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../sampling/index.html">Sampling</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../../../scientific_machine_learning/index.html">Scientific Machine Learning</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../../../scientific_machine_learning/index.html#quickstart">Quickstart</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../scientific_machine_learning/index.html#functional">Functional</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../scientific_machine_learning/index.html#layers">Layers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../scientific_machine_learning/index.html#losses">Losses</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../scientific_machine_learning/index.html#neural-networks">Neural Networks</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../../../scientific_machine_learning/index.html#trainers">Trainers</a><ul class="current">
<li class="toctree-l3 current"><a class="reference internal" href="../../../scientific_machine_learning/trainers/index.html"> Overview</a><ul class="current">
<li class="toctree-l4 current"><a class="reference internal" href="../../../scientific_machine_learning/trainers/index.html#list-of-trainers">List of Trainers</a></li>
</ul>
</li>
<li class="toctree-l3 current"><a class="reference internal" href="../../../scientific_machine_learning/trainers/trainer.html"> Trainer</a><ul class="current">
<li class="toctree-l4"><a class="reference internal" href="../../../scientific_machine_learning/trainers/trainer.html#methods">Methods</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../scientific_machine_learning/trainers/trainer.html#attributes">Attributes</a></li>
<li class="toctree-l4 current"><a class="reference internal" href="../../../scientific_machine_learning/trainers/trainer.html#examples">Examples</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../scientific_machine_learning/trainers/bbb_trainer.html"> BBBTrainer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../scientific_machine_learning/trainers/hmc_trainer.html"> HMCTrainer</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../sensitivity/index.html">Sensitivity</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../stochastic_process/index.html">Stochastic Process</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../surrogates/index.html">Surrogates</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../transformations/index.html">Transformations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../utilities/index.html">Utilities</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../architecture.html">UQpy architecture</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../paper.html">UQpy paper</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../bibliography.html">Bibliography</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../news_doc.html">News</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu"  style="background: #F0F0F0" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">UQpy</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../../../scientific_machine_learning/index.html">Scientific Machine Learning</a></li>
          <li class="breadcrumb-item"><a href="../../../scientific_machine_learning/layers/index.html">Neural Network Layers</a></li>
          <li class="breadcrumb-item"><a href="../../../scientific_machine_learning/layers/dropout_layers.html">List of Probabilistic Dropout Layers</a></li>
          <li class="breadcrumb-item"><a href="index.html">Monte Carlo Dropout Examples</a></li>
      <li class="breadcrumb-item active">Probabilisitc Models with Monte Carlo Dropout</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../../_sources/auto_examples/scientific_machine_learning/mcd_trainer/NeuralNetwork_MCD.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p><a class="reference internal" href="#sphx-glr-download-auto-examples-scientific-machine-learning-mcd-trainer-neuralnetwork-mcd-py"><span class="std std-ref">Go to the end</span></a>
to download the full example code. or to run this example in your browser via Binder</p>
</div>
<section class="sphx-glr-example-title" id="probabilisitc-models-with-monte-carlo-dropout">
<span id="sphx-glr-auto-examples-scientific-machine-learning-mcd-trainer-neuralnetwork-mcd-py"></span><h1>Probabilisitc Models with Monte Carlo Dropout<a class="headerlink" href="#probabilisitc-models-with-monte-carlo-dropout" title="Link to this heading"></a></h1>
<p>This example shows how to create a probabilistic neural network using UQpy’s ProbabilisticDropout layers.</p>
<p>First, we import the necessary modules and, optionally, set UQpy to print logs to the console.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">logging</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">Dataset</span><span class="p">,</span> <span class="n">DataLoader</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">UQpy.scientific_machine_learning</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">sml</span>

<span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># logger = logging.getLogger(&quot;UQpy&quot;)  # Optional, display UQpy logs to console</span>
<span class="c1"># logger.setLevel(logging.INFO)</span>
</pre></div>
</div>
<p>Our neural network will approximate the function <span class="math notranslate nohighlight">\(f(x)=0.4 \sin(4x) + 0.5 \cos(12x) + \epsilon\)</span> over the domain
<span class="math notranslate nohighlight">\(x \in [-1, 1]\)</span>. <span class="math notranslate nohighlight">\(\epsilon\)</span> represents the noise in our measurement defined as the Gaussian random
variable <span class="math notranslate nohighlight">\(\epsilon \sim N(0, 0.05)\)</span>.</p>
<p>Below we define the dataset by subclassing <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.utils.data.Dataset</span></code>.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">SinusoidalDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_samples</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">noise_std</span><span class="o">=</span><span class="mf">0.05</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_samples</span> <span class="o">=</span> <span class="n">n_samples</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">noise_std</span> <span class="o">=</span> <span class="n">noise_std</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">y</span> <span class="o">=</span><span class="mf">0.4</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="mi">4</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="mi">12</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">x</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">y</span> <span class="o">+=</span> <span class="n">torch</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">noise_std</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_samples</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">item</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">x</span><span class="p">[</span><span class="n">item</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">[</span><span class="n">item</span><span class="p">]</span>
</pre></div>
</div>
<p>We define our model as a fully connected feed-forward neural network.
After each hidden layer, we add a <code class="xref py py-class docutils literal notranslate"><span class="pre">ProbabilisticDropout</span></code> layer to randomly set some tensor elements to zero
with probability <span class="math notranslate nohighlight">\(p=1e-3\)</span>. These layers will be <em>inactive</em>  during training,
and will only be turned on during evaluation.</p>
<p>The model is trained using Pytorch’s gradient descent algorithms passed to <code class="xref py py-class docutils literal notranslate"><span class="pre">Trainer</span></code>.
We include a scheduler to control the learning rate.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">width</span> <span class="o">=</span> <span class="mi">30</span>
<span class="n">p</span> <span class="o">=</span> <span class="mf">2e-3</span>
<span class="n">network</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">width</span><span class="p">),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">width</span><span class="p">,</span> <span class="n">width</span><span class="p">),</span>
    <span class="n">sml</span><span class="o">.</span><span class="n">ProbabilisticDropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="n">p</span><span class="p">),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">width</span><span class="p">,</span> <span class="n">width</span><span class="p">),</span>
    <span class="n">sml</span><span class="o">.</span><span class="n">ProbabilisticDropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="n">p</span><span class="p">),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">width</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
<span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">sml</span><span class="o">.</span><span class="n">FeedForwardNeuralNetwork</span><span class="p">(</span><span class="n">network</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>  <span class="c1"># turn off all ProbabilisticDropout layers</span>

<span class="n">dataset</span> <span class="o">=</span> <span class="n">SinusoidalDataset</span><span class="p">()</span>
<span class="n">train_data</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>
<span class="n">scheduler</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">StepLR</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">step_size</span><span class="o">=</span><span class="mi">1_000</span><span class="p">)</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">sml</span><span class="o">.</span><span class="n">Trainer</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">scheduler</span><span class="o">=</span><span class="n">scheduler</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Starting Training...&quot;</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">train_data</span><span class="o">=</span><span class="n">train_data</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">5_000</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;done&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>That’s the hard part done! We defined our dataset, our model, and then fit the model to the data.
The rest of this example plots the model predictions to compare them to the exact solution.
We also show how to activate the dropout layers to compute a probabilistic prediction</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Plot training history</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">semilogy</span><span class="p">(</span><span class="n">trainer</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s2">&quot;train_loss&quot;</span><span class="p">])</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Training Loss&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s2">&quot;Epoch&quot;</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s2">&quot;Loss&quot;</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>

<span class="c1"># Plot model predictions</span>
<span class="n">x_noisy</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">x</span>
<span class="n">y_noisy</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">y</span>
<span class="n">x_exact</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">y_exact</span> <span class="o">=</span> <span class="mf">0.4</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="mi">4</span> <span class="o">*</span> <span class="n">x_exact</span><span class="p">)</span> <span class="o">+</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="mi">12</span> <span class="o">*</span> <span class="n">x_exact</span><span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="c1"># compute deterministic prediction</span>
<span class="n">model</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Model is dropping:&quot;</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">dropping</span><span class="p">)</span>
<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">deterministic_prediction</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x_exact</span><span class="p">)</span>

<span class="c1"># compute probabilistic predictions</span>
<span class="n">model</span><span class="o">.</span><span class="n">drop</span><span class="p">()</span>  <span class="c1"># turn on all dropout layers</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Model is dropping:&quot;</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">dropping</span><span class="p">)</span>
<span class="n">n</span> <span class="o">=</span> <span class="mi">500</span>
<span class="n">samples</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">x_exact</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
    <span class="n">samples</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x_exact</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
<span class="n">quantile_low</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="n">q</span><span class="o">=</span><span class="mf">0.025</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">quantile_high</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="n">q</span><span class="o">=</span><span class="mf">0.975</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x_noisy</span><span class="p">,</span> <span class="n">y_noisy</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Training Data&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
    <span class="n">x_exact</span><span class="p">,</span>
    <span class="n">y_exact</span><span class="p">,</span>
    <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Exact&quot;</span><span class="p">,</span>
    <span class="n">color</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">,</span>
    <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;dashed&quot;</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
    <span class="n">x_exact</span><span class="p">,</span>
    <span class="n">deterministic_prediction</span><span class="p">,</span>
    <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Deterministic Model&quot;</span><span class="p">,</span>
    <span class="n">color</span><span class="o">=</span><span class="s2">&quot;tab:blue&quot;</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span>
    <span class="n">x_exact</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(),</span>
    <span class="n">quantile_low</span><span class="p">,</span>
    <span class="n">quantile_high</span><span class="p">,</span>
    <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Middle 95%&quot;</span><span class="p">,</span>
    <span class="n">color</span><span class="o">=</span><span class="s2">&quot;tab:blue&quot;</span><span class="p">,</span>
    <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Monte Carlo Dropout Predictions&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s2">&quot;x&quot;</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s2">&quot;f(x)&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>


<span class="c1"># Plotting Results</span>
<span class="c1"># x_data = SinusoidalDataset().x.detach()</span>
<span class="c1"># y_data = SinusoidalDataset().y.detach()</span>
<span class="c1"># x_val = torch.linspace(-1, 1, 1000).view(-1, 1).detach()</span>
<span class="c1"># y_val = 0.4 * torch.sin(4 * x_val) + 0.5 * torch.cos(12 * x_val).detach()</span>
<span class="c1"># pred_val = model(x_val).detach()</span>
<span class="c1">#</span>
<span class="c1"># # %% Plot the deterministic model estimates</span>
<span class="c1"># fig, ax = plt.subplots()</span>
<span class="c1"># ax.scatter(x_data, y_data, label=&quot;Data&quot;, color=&quot;black&quot;, s=50)</span>
<span class="c1"># ax.plot(</span>
<span class="c1">#     x_val,</span>
<span class="c1">#     pred_val,</span>
<span class="c1">#     label=&quot;Final Prediction&quot;,</span>
<span class="c1">#     color=&quot;tab:orange&quot;,</span>
<span class="c1"># )</span>
<span class="c1"># ax.plot(</span>
<span class="c1">#     x_val.detach(),</span>
<span class="c1">#     y_val.detach(),</span>
<span class="c1">#     label=&quot;Target&quot;,</span>
<span class="c1">#     color=&quot;black&quot;,</span>
<span class="c1">#     linestyle=&quot;dashed&quot;,</span>
<span class="c1"># )</span>
<span class="c1"># ax.set_title(&quot;Deterministic Prediction&quot;)</span>
<span class="c1"># ax.set(xlabel=&quot;$x$&quot;, ylabel=&quot;$f(x)$&quot;)</span>
<span class="c1"># ax.legend()</span>
<span class="c1"># fig.tight_layout()</span>
<span class="c1">#</span>
<span class="c1"># train_loss = trainer.history[&quot;train_loss&quot;].detach().numpy()</span>
<span class="c1"># fig, ax = plt.subplots()</span>
<span class="c1"># ax.semilogy(train_loss)</span>
<span class="c1"># ax.set_title(&quot;Training Loss&quot;)</span>
<span class="c1"># ax.set(xlabel=&quot;Epoch&quot;, ylabel=&quot;Loss&quot;)</span>
<span class="c1"># fig.tight_layout()</span>
<span class="c1">#</span>
<span class="c1"># # %%</span>
<span class="c1"># model.drop()  # activate the dropout layers</span>
<span class="c1"># n = 1_000</span>
<span class="c1"># samples = torch.zeros(n, len(x_val))</span>
<span class="c1"># for i in range(n):</span>
<span class="c1">#     samples[i, :] = model(x_val).detach().squeeze()</span>
<span class="c1"># mean = torch.mean(samples, dim=1)</span>
<span class="c1"># standard_deviation = torch.std(samples, dim=1)</span>
<span class="c1">#</span>
<span class="c1"># # Plotting Results</span>
<span class="c1"># fig, ax = plt.subplots()</span>
<span class="c1"># ax.plot(x_val, samples[:, 1], &quot;tab:orange&quot;, label=&quot;Prediction 1&quot;)</span>
<span class="c1"># ax.plot(x_val, samples[:, 2], &quot;tab:blue&quot;, label=&quot;Prediction 2&quot;)</span>
<span class="c1"># ax.scatter(x_data, y_data, color=&quot;black&quot;, label=&quot;Data&quot;)</span>
<span class="c1"># ax.plot(x_val, y_val, color=&quot;black&quot;, linestyle=&quot;dashed&quot;, label=&quot;Target&quot;)</span>
<span class="c1"># ax.set_title(&quot;Two Samples from Dropout NN&quot;)</span>
<span class="c1"># ax.set(xlabel=&quot;$x$&quot;, ylabel=&quot;$f(x)$&quot;)</span>
<span class="c1"># ax.legend()</span>
<span class="c1"># fig.tight_layout()</span>
<span class="c1">#</span>
<span class="c1"># # %%</span>
<span class="c1"># fig, ax = plt.subplots()</span>
<span class="c1"># ax.plot(x_val, mean, label=&quot;$\mu$&quot;)</span>
<span class="c1"># ax.fill_between(</span>
<span class="c1">#     x_val.view(-1),</span>
<span class="c1">#     torch.quantile(samples, q=0.025, dim=1),</span>
<span class="c1">#     torch.quantile(samples, q=0.975, dim=1),</span>
<span class="c1">#     label=&quot;95% Range&quot;,</span>
<span class="c1">#     # mean - (3 * standard_deviation),</span>
<span class="c1">#     # mean + (3 * standard_deviation),</span>
<span class="c1">#     # label=&quot;$\mu \pm 3\sigma$,&quot;,</span>
<span class="c1">#     alpha=0.3,</span>
<span class="c1"># )</span>
<span class="c1"># ax.plot(x_val, y_val, label=&quot;Target&quot;, color=&quot;black&quot;)</span>
<span class="c1"># ax.set_title(&quot;Dropout Neural Network 95% Range&quot;)</span>
<span class="c1"># ax.set(xlabel=&quot;x&quot;, ylabel=&quot;f(x)&quot;)</span>
<span class="c1"># ax.legend()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<div class="sphx-glr-footer sphx-glr-footer-example docutils container" id="sphx-glr-download-auto-examples-scientific-machine-learning-mcd-trainer-neuralnetwork-mcd-py">
<div class="binder-badge docutils container">
<a class="reference external image-reference" href="https://mybinder.org/v2/gh/SURGroup/UQpy/master?urlpath=lab/tree/notebooks/auto_examples/scientific_machine_learning/mcd_trainer/NeuralNetwork_MCD.ipynb"><img alt="Launch binder" src="../../../_images/binder_badge_logo31.svg" style="width: 150px;" />
</a>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../../../_downloads/7dcfa43b0e7d7bb064d1d99fd789f089/NeuralNetwork_MCD.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">NeuralNetwork_MCD.ipynb</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../../../_downloads/3742364d1376999686680aa31b5d3ee8/NeuralNetwork_MCD.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">NeuralNetwork_MCD.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-zip docutils container">
<p><a class="reference download internal" download="" href="../../../_downloads/40bbe03dad8156d6c64fc6efc7ac1ce5/NeuralNetwork_MCD.zip"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">zipped:</span> <span class="pre">NeuralNetwork_MCD.zip</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="index.html" class="btn btn-neutral float-left" title="Monte Carlo Dropout Examples" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../../../scientific_machine_learning/layers/fourier_layers.html" class="btn btn-neutral float-right" title="List of Fourier Layers" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2021, Michael D. Shields.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>