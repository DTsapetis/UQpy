{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Sinusoidal Function  (1 random input, scalar output)\n\nIn this example, PCE is used to generate a surrogate model of a sinusoidal function with a single random input and a\nscalar output.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Import necessary libraries.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nimport matplotlib.pyplot as plt\nfrom UQpy.distributions import Uniform\nfrom UQpy.surrogates import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define the sinusoidal function to be approximated.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def sinusoidal_function(x):\n    return x * np.sin(x) / 10.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create a distribution object, generate samples and evaluate the function at the samples.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "np.random.seed(1)\n\ndist = Uniform(loc=0, scale=10)\nn_samples = 200\nx = dist.rvs(n_samples)\ny = sinusoidal_function(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create an object from the PCE class, construct a total-degree polynomial basis given a maximum polynomial degree, and\ncompute the PCE coefficients using least squares regression.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "max_degree = 15\npolynomial_basis = TotalDegreeBasis(dist, max_degree)\nleast_squares = LeastSquareRegression()\npce_lstsq = PolynomialChaosExpansion(polynomial_basis=polynomial_basis, regression_method=least_squares)\n\npce_lstsq.fit(x,y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create an object from the PCE class, construct a total-degree polynomial basis given a maximum polynomial degree, and\ncompute the PCE coefficients using LASSO regression.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "polynomial_basis = TotalDegreeBasis(dist, max_degree)\nlasso = LassoRegression()\npce_lasso = PolynomialChaosExpansion(polynomial_basis=polynomial_basis, regression_method=lasso)\n\npce_lasso.fit(x,y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create an object from the PCE class, construct a total-degree polynomial basis given a maximum polynomial degree, and\ncompute the PCE coefficients using ridge regression.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "polynomial_basis = TotalDegreeBasis(dist, max_degree)\nridge = RidgeRegression()\npce_ridge = PolynomialChaosExpansion(polynomial_basis=polynomial_basis, regression_method=ridge)\n\npce_ridge.fit(x,y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "PCE surrogate is used to predict the behavior of the function at new samples.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "x_test = dist.rvs(100)\nx_test.sort(axis=0)\n\ny_test_lstsq = pce_lstsq.predict(x_test)\ny_test_lasso = pce_lasso.predict(x_test)\ny_test_ridge = pce_ridge.predict(x_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot training data, true function and PCE surrogate\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "n_samples_ = 1000\nx_ = np.linspace(min(x_test), max(x_test), n_samples_)\nf = sinusoidal_function(x_)\n\nplt.figure()\nplt.plot(x_test, y_test_lstsq, 'g', label='PCE predictor - LSTSQ')\nplt.plot(x_test, y_test_lasso, 'r', label='PCE predictor - LASSO')\nplt.plot(x_test, y_test_ridge, 'b', label='PCE predictor - Ridge')\nplt.scatter(x, y, label='training data')\nplt.plot(x_, f, 'm', label='function')\nplt.title('PCE surrogate - prediction accuracy')\nplt.legend(); plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Error Estimation\nConstruct a validation dataset and get the validation error.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# validation sample\nn_samples = 100000\nx_val = dist.rvs(n_samples)\ny_val = sinusoidal_function(x_val).flatten()\n\n# PCE predictions\ny_pce_lstsq = pce_lstsq.predict(x_val).flatten()\ny_pce_lasso = pce_lasso.predict(x_val).flatten()\ny_pce_ridge = pce_ridge.predict(x_val).flatten()\n\n# mean absolute errors\nerror_lstsq = np.sum(np.abs(y_val - y_pce_lstsq))/n_samples\nerror_lasso = np.sum(np.abs(y_val - y_pce_lasso))/n_samples\nerror_ridge = np.sum(np.abs(y_val - y_pce_ridge))/n_samples\n\nprint('Mean absolute error from least squares regression is: ', error_lstsq)\nprint('Mean absolute error from LASSO regression is: ', error_lasso)\nprint('Mean absolute error from ridge regression is: ', error_ridge)\nprint(' ')\n\n# mean relative errors\nerror_lstsq = np.sum( np.abs((y_val - y_pce_lstsq)/y_val) )/n_samples\nerror_lasso = np.sum( np.abs((y_val - y_pce_lasso)/y_val) )/n_samples\nerror_ridge = np.sum( np.abs((y_val - y_pce_ridge)/y_val) )/n_samples\n\nprint('Mean relative error from least squares regression is: ', error_lstsq)\nprint('Mean relative error from LASSO regression is: ', error_lasso)\nprint('Mean relative error from ridge regression is: ', error_ridge)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Moment Estimation\nReturns mean and variance of the PCE surrogate.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "n_mc = 1000000\nx_mc = dist.rvs(n_mc)\ny_mc = sinusoidal_function(x_mc)\nmean_mc = np.mean(y_mc)\nvar_mc = np.var(y_mc)\n\nprint('Moments from least squares regression :', pce_lstsq.get_moments())\nprint('Moments from LASSO regression :', pce_lasso.get_moments())\nprint('Moments from Ridge regression :', pce_ridge.get_moments())\nprint('Moments from Monte Carlo integration: ', mean_mc, var_mc)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}