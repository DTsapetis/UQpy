{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Physics-Informed PCE: Uncertainty Quantification of Euler Beam\n\nIn this example, we use Physics-informed Polynomial Chaos Expansion for approximation and UQ of Euler beam equation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Import necessary libraries.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from UQpy.distributions import Uniform, JointIndependent\nfrom UQpy.surrogates import *\n\n# load PC^2\nfrom UQpy.surrogates.polynomial_chaos.polynomials.TotalDegreeBasis import TotalDegreeBasis\nfrom UQpy.surrogates.polynomial_chaos.physics_informed.ConstrainedPCE import ConstrainedPCE\nfrom UQpy.surrogates.polynomial_chaos.physics_informed.PdeData import PdeData\nfrom UQpy.surrogates.polynomial_chaos.physics_informed.PdePCE import PdePCE\nfrom UQpy.surrogates.polynomial_chaos.physics_informed.Utilities import *\nfrom UQpy.surrogates.polynomial_chaos.physics_informed.ReducedPCE import ReducedPCE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We then define functions used for construction of Physically Constrained PCE (PC $^2$)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Definition of PDE/ODE\ndef pde_func(standardized_sample, pce):\n    der_order = 4\n    deriv_pce = derivative_basis(standardized_sample, pce, derivative_order=der_order, leading_variable=0) * ((2 / 1) ** der_order)\n\n    pde_basis = deriv_pce\n\n    return pde_basis\n\n\n# Definition of the source term\ndef pde_res(standardized_sample):\n    load_s = load(standardized_sample)\n\n    return -load_s[:, 0]\n\n\ndef load(standardized_sample):\n    return const_load(standardized_sample)\n\n\ndef const_load(standardized_sample):\n    l = (1 + (1 + standardized_sample[:, 1]) / 2).reshape(-1, 1)\n    return l\n\n\n# Definition of the function for sampling of boundary conditions\ndef bc_sampling(nsim=1000):\n    # BC sampling\n\n    nsim_half = round(nsim / 2)\n    sample = np.zeros((nsim, 2))\n    real_ogrid_1d = ortho_grid(nsim_half, 1, 0.0, 1.0)[:, 0]\n\n    sample[:nsim_half, 0] = np.zeros(nsim_half)\n    sample[:nsim_half, 1] = real_ogrid_1d\n\n    sample[nsim_half:, 0] = np.ones(nsim_half)\n    sample[nsim_half:, 1] = real_ogrid_1d\n\n    return sample\n\n\n# define sampling and evaluation of BC for estimation of error\ndef bc_res(nsim, pce):\n    physical_sample= np.zeros((2, 2))\n    physical_sample[1, 0] = 1\n    standardized_sample = polynomial_chaos.Polynomials.standardize_sample(physical_sample, pce.polynomial_basis.distributions)\n\n    der_order = 2\n    deriv_pce = np.sum(\n        derivative_basis(standardized_sample, pce, derivative_order=der_order, leading_variable=0) *\n        ((2 / 1) ** der_order) * np.array(pce.coefficients).T, axis=1)\n\n    return deriv_pce\n\n\n# Definition of the reference solution for an error estimation\ndef ref_sol(physical_coordinate, q):\n    return (q + 1) * (-(physical_coordinate ** 4) / 24 + physical_coordinate ** 3 / 12 - physical_coordinate / 24)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Beam equation is parametrized by one deterministic input variable (coordinate $x$) and\nrandom load intensity $q$, both modeled as Uniform random variables.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# number of input variables\n\nnrand = 1\nnvar = 1 + nrand\n\n#   definition of a joint probability distribution\ndist1 = Uniform(loc=0, scale=1)\ndist2 = Uniform(loc=0, scale=1)\nmarg = [dist1, dist2]\njoint = JointIndependent(marginals=marg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The physical domain is defined by $x \\in [0,1]$\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# define geometry of physical space\ngeometry_xmin = [0]\ngeometry_xmax = [1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Boundary conditions are prescribed as\n\n\\begin{align}\\frac{d^2 u(0,q)}{d x^2}=0, \\qquad \\frac{d^2 u(1,q)}{d x^2}=0, \\qquad u(0,q)=0, \\qquad  u(1,q)=0\\end{align}\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# number of BC samples\nnbc = 2 * 10\n\n# derivation orders of prescribed BCs\nder_orders = [0, 2]\n# normals associated to precribed BCs\nbc_normals = [0, 0]\n# sampling of BC points\n\nbc_xtotal = bc_sampling(20)\nbc_ytotal = np.zeros(len(bc_xtotal))\n\nbc_x = [bc_xtotal, bc_xtotal]\nbc_y = [bc_ytotal, bc_ytotal]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here we construct an object containing general physical information (geometry, boundary conditions)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pde_data = PdeData(geometry_xmax, geometry_xmin, der_orders, bc_normals, bc_x, bc_y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Further we construct an object containing PDE physical data and PC $^2$ definitions of PDE\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pde_pce = PdePCE(pde_data, pde_func, pde_source=pde_res, boundary_conditions_evaluate=bc_res)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Get dirichlet boundary conditions from PDE data object that are further used for construction of initial PCE object.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dirichlet_bc = pde_data.dirichlet\nx_train = dirichlet_bc[:, :-1]\ny_train = dirichlet_bc[:, -1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, PC $^2$ is constructed using Karush-Kuhn-Tucker normal equations solved by ordinary least squares and\nLeast Angle Regression.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "least_squares = LeastSquareRegression()\np = 9\n\nPCEorder = p\npolynomial_basis = TotalDegreeBasis(joint, PCEorder, hyperbolic=1)\n\n#  create initial PCE object containing basis, regression method and dirichlet BC\ninitpce = PolynomialChaosExpansion(polynomial_basis=polynomial_basis, regression_method=least_squares)\ninitpce.set_data(x_train, y_train)\n\n# construct a PC^2 object combining pde_data, pde_pce and initial PCE objects\npcpc = ConstrainedPCE(pde_data, pde_pce, initpce)\n# get coefficients of PC^2 by least angle regression\npcpc.lar()\n\n# get coefficients of PC^2 by ordinary least squares\npcpc.ols()\n\n# evaluate errors of approximations\nreal_ogrid = ortho_grid(100, nvar, 0.0, 1.0)\nyy_val_pce = pcpc.lar_pce.predict(real_ogrid).flatten()\nyy_val_pce_ols = pcpc.initial_pce.predict(real_ogrid).flatten()\nyy_val_true = ref_sol(real_ogrid[:, 0], real_ogrid[:, 1]).flatten()\n\nerr = np.abs(yy_val_pce - yy_val_true)\ntot_err = np.sum(err)\nprint('\\nTotal approximation error by PC^2-LAR: ', tot_err)\n\nerr_ols = np.abs(yy_val_pce_ols - yy_val_true)\ntot_err_ols = np.sum(err_ols)\nprint('Total approximation error by PC^2-OLS: ', tot_err_ols)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Once the PC $^2$ is constructed, we use ReducedPce class to filter out influence of deterministic variable in UQ\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "reduced_pce = ReducedPCE(pcpc.lar_pce, n_deterministic=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "ReducedPce is used for estimation of local statistical moments and quantiles $\\pm2\\sigma$\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "coeff_res = []\nvar_res = []\nmean_res = []\nvartot_res = []\nlower_quantiles_modes = []\nupper_quantiles_modes = []\n\nn_derivations = 4\nsigma_mult = 2\nbeam_x = np.arange(0, 101) / 100\n\nfor x in beam_x:\n    mean = np.zeros(n_derivations + 1)\n    var = np.zeros(n_derivations + 1)\n    variances = np.zeros((n_derivations + 1, nrand))\n    lq = np.zeros((1 + n_derivations, nrand))\n    uq = np.zeros((1 + n_derivations, nrand))\n    for d in range(1 + n_derivations):\n        if d == 0:\n            coeff = (reduced_pce.evaluate_coordinate(np.array(x), return_coefficients=True))\n        else:\n            coeff = reduced_pce.derive_coordinate(np.array(x), derivative_order=d, leading_variable=0,\n                                                  return_coefficients=True,\n                                                  derivative_multiplier=transformation_multiplier(pde_data, 0, d))\n        mean[d] = coeff[0]\n        var[d] = np.sum(coeff[1:] ** 2)\n        variances[d, :] = reduced_pce.variance_contributions(coeff)\n\n        for e in range(nrand):\n            lq[d, e] = mean[d] + sigma_mult * np.sqrt(np.sum(variances[d, :e + 1]))\n            uq[d, e] = mean[d] - sigma_mult * np.sqrt(np.sum(variances[d, :e + 1]))\n\n    lower_quantiles_modes.append(lq)\n    upper_quantiles_modes.append(uq)\n    var_res.append(variances)\n    mean_res.append(mean)\n    vartot_res.append(var)\n\nmean_res = np.array(mean_res)\nvartot_res = np.array(vartot_res)\nvar_res = np.array(var_res)\nlower_quantiles_modes = np.array(lower_quantiles_modes)\nupper_quantiles_modes = np.array(upper_quantiles_modes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "PC $^2$ and corresponding Reduced PCE can be further used for local UQ. Obtained results are depicted in figure.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# plot results\nimport matplotlib.pyplot as plt\n\nfig, ax = plt.subplots(1, 4, figsize=(14.5, 3))\ncolors = ['black', 'blue', 'green', 'red']\n\nfor d in range(2, 1 + n_derivations):\n    ax[d - 1].plot(beam_x, mean_res[:, d], color=colors[d - 1])\n    ax[d - 1].plot(beam_x, mean_res[:, d] + sigma_mult * np.sqrt(vartot_res[:, d]), color=colors[d - 1])\n    ax[d - 1].plot(beam_x, mean_res[:, d] - sigma_mult * np.sqrt(vartot_res[:, d]), color=colors[d - 1])\n\n    ax[d - 1].plot(beam_x, lower_quantiles_modes[:, d, 0], '--', alpha=0.7, color=colors[d - 1])\n    ax[d - 1].plot(beam_x, upper_quantiles_modes[:, d, 0], '--', alpha=0.7, color=colors[d - 1])\n    ax[d - 1].fill_between(beam_x, lower_quantiles_modes[:, d, 0], upper_quantiles_modes[:, d, 0],\n                           facecolor=colors[d - 1], alpha=0.05)\n\n    ax[d - 1].plot(beam_x, np.zeros(len(beam_x)), color='black')\n\nax[0].plot(beam_x, mean_res[:, 0], color=colors[0])\nax[0].plot(beam_x, mean_res[:, 0] + sigma_mult * np.sqrt(vartot_res[:, 0]), color=colors[0])\nax[0].plot(beam_x, mean_res[:, 0] - sigma_mult * np.sqrt(vartot_res[:, 0]), color=colors[0])\n\nax[0].plot(beam_x, lower_quantiles_modes[:, 0, 0], '--', alpha=0.7, color=colors[0])\nax[0].plot(beam_x, upper_quantiles_modes[:, 0, 0], '--', alpha=0.7, color=colors[0])\nax[0].fill_between(beam_x, lower_quantiles_modes[:, 0, 0], upper_quantiles_modes[:, 0, 0],\n                   facecolor=colors[0], alpha=0.05)\n\nax[0].plot(beam_x, np.zeros(len(beam_x)), color='black')\n\nax[3].invert_yaxis()\nax[1].invert_yaxis()\n\nax[3].set_title(r'Load $\\frac{\\partial^4 w}{\\partial x^4}$', y=1.04)\nax[2].set_title(r'Shear Force $\\frac{\\partial^3 w}{\\partial x^3}$', y=1.04)\nax[1].set_title(r'Bending Moment $\\frac{\\partial^2 w}{\\partial x^2}$', y=1.04)\nax[0].set_title(r'Deflection $w$', y=1.04)\n\nfor axi in ax.flatten():\n    axi.set_xlabel(r'$x$')\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}