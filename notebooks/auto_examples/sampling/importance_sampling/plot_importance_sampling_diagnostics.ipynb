{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Diagnostics for Importance Sampling\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This notebook illustrates the use of some simple diagnostics for Importance Sampling. For IS, in extreme settings\nonly a few samples may have a significant weight, yielding poor approximations of the target pdf $p(x)$. A popular\ndiagnostics is the Effective Sample Size (ESS), which is theoretically defined as the number of independent samples\ngenerated directly form the target distribution that are required to obtain an estimator with same variance as the\none obtained from IS. Heuristically, ESS approximates how many i.i.d. samples, drawn from the target, are equivalent\nto $N$ weighted samples drawn from the IS or MCMC approximation.\n\nAn approximation of the ESS is given by [1]:\n\n\\begin{align}ESS = \\frac{1}{\\sum \\tilde{w}^2}\\end{align}\n\nwhere $\\tilde{w}$ are the normalized weights.\n\n[1] *Sequential Monte Carlo Methods in Practice*, A. Doucet, N. de Freitas, and N. Gordon, 2001, Springer, New York\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from UQpy.distributions import Uniform, JointIndependent\nfrom UQpy.sampling import ImportanceSampling\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ndef log_Rosenbrock(x, param):\n    return (-(100 * (x[:, 1] - x[:, 0] ** 2) ** 2 + (1 - x[:, 0]) ** 2) / param)\n\nproposal = JointIndependent([Uniform(loc=-8, scale=16), Uniform(loc=-10, scale=60)])\nprint(proposal.get_parameters())\n\nw = ImportanceSampling(log_pdf_target = log_Rosenbrock, args_target = (20,),\n                       proposal = proposal, nsamples=5000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Look at distribution of weights\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print('max_weight = {}, min_weight = {} \\n'.format(max(w.weights), min(w.weights)))\n\nfig, ax = plt.subplots(figsize=(8, 3))\nax.scatter(w.weights, np.zeros((np.size(w.weights),)), s=w.weights * 600, marker='o')\nax.set_xlabel('weights')\nax.set_title('Normalized weights out of importance sampling')\nax.tick_params(which='both', left=False, labelleft=False)  # labels along the bottom edge are off\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Compute the effective sample size\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "effective_sample_size = 1. / np.sum(w.weights ** 2, axis=0)\n\nprint('Effective sample size is ne={}, out of a total number of samples={} \\n'.\n      format(effective_sample_size, np.size(w.weights)))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}