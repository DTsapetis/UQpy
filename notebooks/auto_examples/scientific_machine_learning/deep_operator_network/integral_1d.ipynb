{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Learning the 1D Integral Operator\n\nIn this example, we train a Deep Operator Network to learn the operator $\\mathcal{L}f(x) = \\int f(x) dx$.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this example we will approximate the integral operator $\\mathcal{L}f(x) = \\int f(x) dx$\nUsing a Deep Operator Network. This example\n\n1. Generates training data from a stochastic process\n2. Defines the architecture of a Deep Operator Network\n3. Fits the network parameters to the training data\n4. Visualizes the results\n\nFirst, import the necessary modules.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Default imports\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nplt.style.use(\"ggplot\")\n\n# UQpy imports\nimport UQpy.scientific_machine_learning as sml\nfrom UQpy.stochastic_process import SpectralRepresentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**1. Generate Training Data**\n\nWe generate random functions using the stochastic process module in UQpy.\nThe stochastic process is sampled at 100 points over  using the function ``srm_samples``.\nWe denote these input functions $f$. They are sampled at 100 sensing points $x$\non the interval $[0, 1]$.\nThe operator $\\mathcal{L}f(x) = \\int f(x) dx$ is approximated using the function ``operator`` to\nnumerically approximate the integral of $f$ using the cumulative summation.\nThe class ``DONDataSet`` formats the dataset for training. It does not compute any new information.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def srm_samples(n_samples: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"Sample a 1D Gaussian process using the Spectral Representation Method\n\n    :param n_samples: Number of samples. Each sample is one row\n    :return: time, samples\n    \"\"\"\n    max_time = 1\n    n_time = 100\n    max_frequency = 8 * np.pi\n    n_frequency = 32\n\n    delta_time = max_time / n_time\n    delta_frequency = max_frequency / n_frequency\n    frequency = np.linspace(0, max_frequency - delta_frequency, num=n_frequency)\n    time = np.linspace(0, max_time - delta_time, num=n_time)\n    power_spectrum = np.exp(-2 * frequency**2)\n    srm = SpectralRepresentation(\n        n_samples, power_spectrum, delta_time, delta_frequency, n_time, n_frequency\n    )\n    return (\n        torch.tensor(time, dtype=torch.float).reshape(-1, 1),\n        torch.tensor(srm.samples, dtype=torch.float).squeeze(),\n    )\n\n\ndef operator(x: torch.Tensor, u_x: torch.Tensor) -> torch.Tensor:\n    \"\"\"Numerically approximate the integral operator\n\n    :param x: Sensing points at which the function :math:`u` is evalated\n    :param u_x: Evaluations of the function :math:`u` at points :math:`x`\n    :return: Cumulative sum of ``u_x``\n    \"\"\"\n    return torch.cumsum(u_x, axis=1) * (x[1] - x[0])\n\n\nclass DONDataSet(Dataset):\n    \"\"\"Format the data for UQpy Trainer\"\"\"\n\n    def __init__(self, x, u_x, gu_x):\n        self.x = x\n        self.u_x = u_x\n        self.gu_x = gu_x\n\n    def __len__(self):\n        return int(self.x.shape[0])\n\n    def __getitem__(self, i):\n        return self.x, self.u_x[i, :], self.gu_x[i, :]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**2. Initialize Deep Operator Network**\n\nA Deep Operator Network is defined using the branch network, that encodes information about the domain $x$,\nand the trunk network, that encodes information about the transformation $\\mathcal{L}:f \\mapsto \\int f$.\nThis network maps a 1D function sampled at 100 points.\nThe width of each hidden layer in the network is given in ``width`` and the final width of the branch\nand trunk networks before they are combined is given in ``final_width``.\n\nThe branch and trunk networks can be defined using a ``torch.nn.Module`` or any subclass of it.\nHere we use the ``torch.nn.Sequential`` class to define the networks.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "n_points = 100\nn_dimension = 1\nwidth = 20\nfinal_width = 100  # Number of nodes on output of branch and trunk network\nbranch_network = nn.Sequential(\n    nn.Linear(n_points, width),\n    nn.ReLU(),\n    nn.Linear(width, width),\n    nn.ReLU(),\n    nn.Linear(width, final_width),\n)\ntrunk_network = nn.Sequential(\n    nn.Linear(n_dimension, width),\n    nn.ReLU(),\n    nn.Linear(width, width),\n    nn.ReLU(),\n    nn.Linear(width, final_width),\n    nn.ReLU(),\n)\nmodel = sml.DeepOperatorNetwork(branch_network, trunk_network)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**3. Train the network on the data**\n\nThe ``Trainer`` class organizes the model, data, and a pytorch optimization algorithm to learn the model parameters.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "x, f_x = srm_samples(300)\nLf_x = operator(x, f_x)\ntrain_data = DataLoader(DONDataSet(x, f_x, Lf_x), batch_size=20, shuffle=True)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\ntrainer = sml.Trainer(model, optimizer)\ntrainer.run(train_data=train_data, epochs=1_000, tolerance=1e-6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**4. Visualize the results**\n\nFinally, we plot the loss history and the predictions made by the optimized network.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Plot loss history\ntrain_loss = trainer.history[\"train_loss\"].detach().numpy()\nfig, ax = plt.subplots()\nax.semilogy(train_loss)\nax.set_title(\"Training Loss of Deep Operator Network\")\nax.set(xlabel=\"Epoch\", ylabel=\"Loss\")\n\n# Plot deep operator network prediction and exact solution\ncolors = (\"tab:blue\", \"tab:orange\", \"tab:green\")\nx_plot = x.detach().numpy().squeeze()\nfig, ax = plt.subplots()\nfor i in range(3):\n    prediction = model(x, f_x[i, :])\n    ax.plot(\n        x_plot,\n        Lf_x[i, :].detach().numpy(),\n        label=f\"$g_{i}:=\\mathcal{{L}}f_{i} (x)$\",\n        color=colors[i],\n        linestyle=\"dashed\",\n    )\n    ax.plot(\n        x_plot,\n        prediction.detach().numpy(),\n        label=f\"DoN $\\hat{{g}}_{i}$\",\n        color=colors[i],\n    )\nax.set_title(\"Deep Operator Network Predictions\")\nax.legend()\n\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}