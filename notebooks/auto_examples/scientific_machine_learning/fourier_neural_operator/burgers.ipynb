{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Learning the Burgers' Operator\n\nIn this example, we train a Fourier Neural Operator to learn the mapping $y(x, 0) \\mapsto y(x, 0.5)$\nwhere $y(x,t)$ is the solution to the Burgers' equation given by\n\n\\begin{align}\\frac{\\partial}{\\partial t}u(x, t) + u(x, t) \\frac{\\partial}{\\partial x} u(x, t) = \\nu \\frac{\\partial^2}{\\partial x^2} u(x,t)\\end{align}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We learn the mapping from the initial condition $y(x, 0)$ to a point at time $t=0.5$.\nThe training data for this example was computed separately and is available on GitHub.\n\nFirst, import the necessary modules.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import logging\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nimport matplotlib.pyplot as plt\nimport UQpy.scientific_machine_learning as sml\n\ntorch.manual_seed(123)\n\nplt.style.use(\"ggplot\")\nlogger = logging.getLogger(\"UQpy\")\nlogger.setLevel(logging.INFO)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Below we define the data and architecture of our neural operator as subclasses of PyTorch objects.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class BurgersDataset(Dataset):\n\n    def __init__(self, filename_initial_condition: str, filename_solution: str):\n        r\"\"\"Construct a dataset for training a FNO to learn the Burgers' operator :math:`\\mathcal{B}:y(x,0) \\to y(x, t^*)`\n\n        :param filename_initial_condition: Relative path to the `.pt` file containing a torch tensor of shape :math:`(N_\\text{samples}, 1, N_x)`\n        :param filename_solution: Relative path to the `.pt` file containing a torch tensor of shape :math:`(N_\\text{samples}, 1, N_x, N_t)`\n        \"\"\"\n\n        self.filename_initial_condition = filename_initial_condition\n        self.filename_solution = filename_solution\n        self.initial_conditions = torch.load(self.filename_initial_condition)\n        self.burgers_solution = torch.load(self.filename_solution)\n        self.n_samples = self.initial_conditions.size(0)\n\n    def __len__(self):\n        return self.n_samples\n\n    def __getitem__(self, item):\n        return self.initial_conditions[item], self.burgers_solution[item]\n\n\nclass FourierNeuralOperator(nn.Module):\n\n    def __init__(self):\n        \"\"\"Construct a Bayesian FNO\n\n        The lifting layers a single, deterministic, and fully connected linear layer.\n        There are four Bayesian Fourier layers performing a 1d Fourier\n        transform with ReLU activation functions and batch normalization in between.\n        The projection layers are also a single, deterministic, and fully connected linear layer.\n        \"\"\"\n        super().__init__()\n        modes = 16\n        width = 8\n        self.lifting_layers = nn.Sequential(\n            sml.Permutation((0, 2, 1)),\n            nn.Linear(1, width),\n            sml.Permutation((0, 2, 1)),\n        )\n        self.fourier_blocks = nn.Sequential(\n            sml.Fourier1d(width, modes),\n            nn.ReLU(),\n            sml.Fourier1d(width, modes),\n            nn.ReLU(),\n            sml.Fourier1d(width, modes),\n            nn.ReLU(),\n            sml.Fourier1d(width, modes),\n        )\n        self.projection_layers = nn.Sequential(\n            sml.Permutation((0, 2, 1)),\n            nn.Linear(width, 1),\n            sml.Permutation((0, 2, 1)),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        \"\"\"Forward computational call of the FNO.\n\n        Apply the lifting layers, then theFourier blocks, and finally projection layers.\n\n        :param x: Tensor of shape :math:`(N, C, L)`\n        :return: Tensor of shape :math:`(N, C, L)`\n        \"\"\"\n        x = self.lifting_layers(x)\n        x = self.fourier_blocks(x)\n        x = self.projection_layers(x)\n        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We create two instances of the :code:`BurgersDataset` class, one for training data and one for testing data.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "train_dataset = BurgersDataset(\n    \"initial_conditions_train.pt\",\n    \"burgers_solutions_train.pt\",\n)\ntest_dataset = BurgersDataset(\n    \"initial_conditions_test.pt\",\n    \"burgers_solutions_test.pt\",\n)\ntrain_data = DataLoader(train_dataset, batch_size=100, shuffle=True)\ntest_data = DataLoader(test_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, we are ready to instantiate the model and train is using the Adam optimizer\nand UQpy's :py:class:`sml.Trainer`.\nThe model is quite small, with only a few thousand parameters,\nand we only train for 100 epochs to save on computational time.\nIn many applications much larger Fourier neural operators are needed and are trained for longer.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model = FourierNeuralOperator()\nprint(model)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.1)\ntrainer = sml.Trainer(model, optimizer, scheduler=scheduler)\ntrainer.run(train_data=train_data, test_data=test_data, epochs=100)\n# torch.save(model.state_dict(), \"fno_state_dict.pt\")  # optionally save the trained model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The hard part is done! The rest of this example plots the loss history and a prediction from the trained model.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# plot loss history\nfig, ax = plt.subplots()\nax.semilogy(trainer.history[\"train_loss\"], label=\"Train Loss\")\nax.semilogy(trainer.history[\"test_loss\"], label=\"Test NLL\")\nax.set_title(\"Deterministic FNO Training History\")\nax.set(xlabel=\"Epoch\", ylabel=\"MSE\")\nax.legend()\nfig.tight_layout()\n\n# plot FNO prediction\n\n# optional, load weights from save file. fno_state_dict.pt is available on our GitHub.\n# model.load_state_dict(torch.load(\"fno_state_dict.pt\", weights_only=True))\n\nx = torch.linspace(0.0, 1.0, 256)  # spacial domain\nfig, ax = plt.subplots()\ninitial_condition, burgers_solution = train_dataset[0:1]\nwith torch.no_grad():\n    prediction = model(initial_condition)\n\ninitial_condition = initial_condition.squeeze()\nburgers_solution = burgers_solution.squeeze()\nprediction = prediction.squeeze()\nax.plot(x, initial_condition, label=\"$y(x,0)$\", color=\"black\", linestyle=\"dashed\")\nax.plot(\n    x,\n    burgers_solution,\n    label=\"$y(x, 0.5)$\",\n    color=\"black\",\n)\nax.plot(x, prediction, label=\"FNO $\\hat{y}(x, 0.5)$\", color=\"tab:blue\")\nax.set_title(\"Deterministic FNO on Training Data\", loc=\"left\")\nax.set(ylabel=\"$y(x, t)$\", xlabel=\"Time $t$\")\nax.legend(fontsize=\"small\", ncols=2)\n\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}