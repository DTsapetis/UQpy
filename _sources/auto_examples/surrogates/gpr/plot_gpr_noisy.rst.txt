
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/surrogates/gpr/plot_gpr_noisy.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        :ref:`Go to the end <sphx_glr_download_auto_examples_surrogates_gpr_plot_gpr_noisy.py>`
        to download the full example code. or to run this example in your browser via Binder

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_surrogates_gpr_plot_gpr_noisy.py:


Gaussian Process with noisy output
======================================================================

.. GENERATED FROM PYTHON SOURCE LINES 9-11

This jupyter script shows the performance of GaussianProcessRegressor class in the UQpy. A training data is generated
using a function (:math:`f(x)`, as defined below), which is used to train a surrogate model.

.. GENERATED FROM PYTHON SOURCE LINES 16-18

Import the necessary modules to run the example script. Notice that FminCobyla is used here, to solve the MLE
optimization problem with constraints.

.. GENERATED FROM PYTHON SOURCE LINES 21-34

.. code-block:: Python


    import numpy as np
    import matplotlib.pyplot as plt
    import warnings

    from UQpy.utilities import RBF

    warnings.filterwarnings('ignore')
    from UQpy.utilities.MinimizeOptimizer import MinimizeOptimizer
    from UQpy.surrogates.gaussian_process.regression_models.LinearRegression import LinearRegression
    from UQpy.surrogates import GaussianProcessRegression









.. GENERATED FROM PYTHON SOURCE LINES 35-38

Consider the following function :math:`f(x)`.

.. math:: f(x) = \frac{1}{100} + \frac{5}{8}(2x-1)^4[(2x-1)^2 + 4\sin{(5 \pi x)^2}], \quad \quad x \in [0,1]

.. GENERATED FROM PYTHON SOURCE LINES 41-47

.. code-block:: Python


    def funct(x):
        y = (1 / 100) + (5 / 8) * ((2 * x - 1) ** 4) * (((2 * x - 1) ** 2) + 4 * np.sin(5 * np.pi * x) ** 2)
        return y









.. GENERATED FROM PYTHON SOURCE LINES 48-49

Define the training data set. The following 13 points have been used to fit the GP.

.. GENERATED FROM PYTHON SOURCE LINES 52-56

.. code-block:: Python


    X_train = np.array([0, 0.06, 0.08, 0.26, 0.27, 0.4, 0.52, 0.6, 0.68, 0.81, 0.9, 0.925, 1]).reshape(-1, 1)
    y_train = funct(X_train)








.. GENERATED FROM PYTHON SOURCE LINES 57-58

Define the test data.

.. GENERATED FROM PYTHON SOURCE LINES 61-66

.. code-block:: Python


    X_test = np.linspace(0, 1, 100).reshape(-1, 1)
    y_test = funct(X_test)









.. GENERATED FROM PYTHON SOURCE LINES 67-74

Train GPR
~~~~~~~~~~~~~
- Noise
- No Constraints

Define kernel used to define the covariance matrix. Here, the application of Radial Basis Function (RBF) kernel is
demonstrated.

.. GENERATED FROM PYTHON SOURCE LINES 77-81

.. code-block:: Python


    kernel2 = RBF()









.. GENERATED FROM PYTHON SOURCE LINES 82-83

Define the optimizer used to identify the maximum likelihood estimate.

.. GENERATED FROM PYTHON SOURCE LINES 86-91

.. code-block:: Python


    bounds_2 = [[10**(-3), 10**3], [10**(-3), 10**2], [10**(-3), 10**(2)]]
    optimizer2 = MinimizeOptimizer(bounds=bounds_2)









.. GENERATED FROM PYTHON SOURCE LINES 92-94

Define the 'GaussianProcessRegressor' class object, the input attributes defined here are kernel, optimizer, initial
estimates of hyperparameters and number of times MLE is identified using random starting point.

.. GENERATED FROM PYTHON SOURCE LINES 97-102

.. code-block:: Python


    gpr2 = GaussianProcessRegression(kernel=kernel2, hyperparameters=[1, 1, 0.1], optimizer=optimizer2,
                                     optimizations_number=10, noise=True, regression_model=LinearRegression())









.. GENERATED FROM PYTHON SOURCE LINES 103-104

Call the 'fit' method to train the surrogate model (GPR).

.. GENERATED FROM PYTHON SOURCE LINES 107-110

.. code-block:: Python


    gpr2.fit(X_train, y_train)








.. GENERATED FROM PYTHON SOURCE LINES 111-112

The maximum likelihood estimates of the hyperparameters are as follows:

.. GENERATED FROM PYTHON SOURCE LINES 115-123

.. code-block:: Python


    print(gpr2.hyperparameters)

    print('Length Scale: ', gpr2.hyperparameters[0])
    print('Process Variance: ', gpr2.hyperparameters[1])
    print('Noise Variance: ', gpr2.hyperparameters[2])






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    [0.07355892 0.50023893 0.001     ]
    Length Scale:  0.07355891628870326
    Process Variance:  0.5002389288479564
    Noise Variance:  0.001




.. GENERATED FROM PYTHON SOURCE LINES 124-126

Use 'predict' method to compute surrogate prediction at the test samples. The attribute 'return_std' is a boolean
indicator. If 'True', 'predict' method also returns the standard error at the test samples.

.. GENERATED FROM PYTHON SOURCE LINES 129-133

.. code-block:: Python


    y_pred2, y_std2 = gpr2.predict(X_test, return_std=True)









.. GENERATED FROM PYTHON SOURCE LINES 134-136

The plot shows the test function in dashed red line and 13 training points are represented by blue dots. Also, blue
curve shows the GPR prediction for $x \in (0, 1)$ and yellow shaded region represents 95% confidence interval.

.. GENERATED FROM PYTHON SOURCE LINES 139-156

.. code-block:: Python


    fig, ax = plt.subplots(figsize=(8.5,7))
    ax.plot(X_test,y_test,'r--',linewidth=2,label='Test Function')
    ax.plot(X_train,y_train,'bo',markerfacecolor='b', markersize=10, label='Training Data')
    ax.plot(X_test,y_pred2,'b-', lw=2, label='GP Prediction')
    ax.plot(X_test, np.zeros((X_test.shape[0],1)))
    ax.fill_between(X_test.flatten(), y_pred2-1.96*y_std2,
                    y_pred2+1.96*y_std2,
                    facecolor='yellow',label='95% CI')
    ax.tick_params(axis='both', which='major', labelsize=12)
    ax.set_xlabel('x', fontsize=15)
    ax.set_ylabel('f(x)', fontsize=15)
    ax.set_ylim([-0.3,1.8])
    plt.title('GP Surrogate (Noise, No Constraints)')
    ax.legend(loc="upper right",prop={'size': 12});
    plt.grid()
    plt.show()



.. image-sg:: /auto_examples/surrogates/gpr/images/sphx_glr_plot_gpr_noisy_001.png
   :alt: GP Surrogate (Noise, No Constraints)
   :srcset: /auto_examples/surrogates/gpr/images/sphx_glr_plot_gpr_noisy_001.png
   :class: sphx-glr-single-img






.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (0 minutes 0.421 seconds)


.. _sphx_glr_download_auto_examples_surrogates_gpr_plot_gpr_noisy.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: binder-badge

      .. image:: images/binder_badge_logo.svg
        :target: https://mybinder.org/v2/gh/SURGroup/UQpy/master?urlpath=lab/tree/notebooks/auto_examples/surrogates/gpr/plot_gpr_noisy.ipynb
        :alt: Launch binder
        :width: 150 px

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: plot_gpr_noisy.ipynb <plot_gpr_noisy.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: plot_gpr_noisy.py <plot_gpr_noisy.py>`

    .. container:: sphx-glr-download sphx-glr-download-zip

      :download:`Download zipped: plot_gpr_noisy.zip <plot_gpr_noisy.zip>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
