{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Active Kriging-Monte Carlo Simulation Example 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Katiana Kontolati \\\n",
    "Date: May 25, 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, Monte Carlo Sampling is used to generate samples from Uniform distribution and new samples are generated adaptively, using EIF (Expected Improvement Function) as the learning criteria."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Branin-Hoo function\n",
    "\n",
    "### Decription:\n",
    "\n",
    ">  - Dimensions: 2\n",
    ">  - This function is usually evaluated on the square $x_1 \\in [-5, 10], \\ x_2 \\in [0, 15]$\n",
    ">  - The function has two local minima and one global minimum\n",
    ">  - Reference: Forrester, A., Sobester, A., & Keane, A. (2008). Engineering design via surrogate modelling: a practical guide. Wiley.\n",
    "\n",
    "> $\\displaystyle f(x) = a(x_2-bx_1^2 + cx_1 -r)^2 + s(1-t)\\cos(x_1) + s + 5x_1$\n",
    "> <br>\n",
    "> <br>\n",
    "> where the recommended values of a, b, c, r, s and t are: $a = 1,\\ b = 5.1/(4\\pi^2),\\ c = 5/\\pi, \\ r = 6, \\ s = 10, \\ t = 1/(8\\pi)$\n",
    "\n",
    "<img src=\"branin.png\" alt=\"branin.png\" height=\"350\" width=\"400\" align=left>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the necessary libraries. Here we import standard libraries such as numpy, matplotlib and other necessary library for plots, but also need to import the MCS, AKMCS, Kriging and RunModel class from UQpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/UQpy_39/lib/python3.9/site-packages/beartype/_util/hint/pep/utilpeptest.py:396: BeartypeDecorHintPepDeprecatedWarning: Type hint typing.List[typing.Callable] deprecated by PEP 585. To resolve this, globally replace this hint by the equivalent PEP 585 type hint (e.g., \"typing.List[int]\" by \"list[int]\"). See also:\n",
      "    https://www.python.org/dev/peps/pep-0585\n",
      "  warn(warning_message, BeartypeDecorHintPepDeprecatedWarning)\n",
      "/opt/anaconda3/envs/UQpy_39/lib/python3.9/site-packages/beartype/_util/hint/pep/utilpeptest.py:396: BeartypeDecorHintPepDeprecatedWarning: Type hint typing.Callable deprecated by PEP 585. To resolve this, globally replace this hint by the equivalent PEP 585 type hint (e.g., \"typing.List[int]\" by \"list[int]\"). See also:\n",
      "    https://www.python.org/dev/peps/pep-0585\n",
      "  warn(warning_message, BeartypeDecorHintPepDeprecatedWarning)\n",
      "/opt/anaconda3/envs/UQpy_39/lib/python3.9/site-packages/beartype/_util/hint/pep/utilpeptest.py:396: BeartypeDecorHintPepDeprecatedWarning: Type hint typing.Callable deprecated by PEP 585. To resolve this, globally replace this hint by the equivalent PEP 585 type hint (e.g., \"typing.List[int]\" by \"list[int]\"). See also:\n",
      "    https://www.python.org/dev/peps/pep-0585\n",
      "  warn(warning_message, BeartypeDecorHintPepDeprecatedWarning)\n",
      "/opt/anaconda3/envs/UQpy_39/lib/python3.9/site-packages/beartype/_util/hint/pep/utilpeptest.py:396: BeartypeDecorHintPepDeprecatedWarning: Type hint typing.List[typing.Union[UQpy.sampling.ImportanceSampling.ImportanceSampling, UQpy.sampling.mcmc.baseclass.MCMC.MCMC]] deprecated by PEP 585. To resolve this, globally replace this hint by the equivalent PEP 585 type hint (e.g., \"typing.List[int]\" by \"list[int]\"). See also:\n",
      "    https://www.python.org/dev/peps/pep-0585\n",
      "  warn(warning_message, BeartypeDecorHintPepDeprecatedWarning)\n",
      "The selected optimizer method does not support bounds and thus will be ignored.\n",
      "The selected optimizer method does not support bounds and thus will be ignored.\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "from UQpy.surrogates import Kriging\n",
    "from UQpy.sampling import MonteCarloSampling, AdaptiveKriging\n",
    "from UQpy.RunModel import RunModel\n",
    "from UQpy.distributions import Uniform\n",
    "from BraninHoo import function\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "import time\n",
    "from UQpy.optimization.MinimizeOptimizer import MinimizeOptimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using UQpy MCS class to generate samples for two random variables, which are uniformly distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "marginals = [Uniform(loc=-5, scale=15), Uniform(loc=0, scale=15)]\n",
    "x = MonteCarloSampling(distributions=marginals, nsamples=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RunModel class is used to define an object to evaluate the model at sample points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmodel = RunModel(model_script='BraninHoo.py', vec=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Krig class defines an object to generate an surrogate model for a given set of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from UQpy.surrogates.kriging.regression_models import Linear\n",
    "from UQpy.surrogates.kriging.correlation_models import Exponential\n",
    "optimizer = MinimizeOptimizer(method=\"L-BFGS-B\")\n",
    "K = Kriging(regression_model=Linear(), correlation_model=Exponential(),optimizer=optimizer,\n",
    "            correlation_model_parameters=[1, 1], optimizations_number=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose an appropriate learning function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from UQpy.sampling.adaptive_kriging_functions.ExpectedImprovement import ExpectedImprovement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AKMCS class is used to generate new sample using 'U-function' as active learning function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dimitris/PycharmProjects/dimtsap/UQpy/src/UQpy/optimization/MinimizeOptimizer.py:24: OptimizeWarning: Unknown solver options: catol\n",
      "  return minimize(function, initial_guess, args=args,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.93475D+01    |proj g|=  6.64901D-01\n",
      "\n",
      "At iterate    1    f=  1.92649D+01    |proj g|=  2.01249D-01\n",
      "\n",
      "At iterate    2    f=  1.92519D+01    |proj g|=  1.31846D-01\n",
      "\n",
      "At iterate    3    f=  1.92492D+01    |proj g|=  4.07029D-02\n",
      "\n",
      "At iterate    4    f=  1.92490D+01    |proj g|=  2.98377D-03\n",
      "\n",
      "True\n",
      "[3.84876863e+02 2.40743445e+06]\n",
      "At iterate    5    f=  1.92490D+01    |proj g|=  1.93344D-04\n",
      "\n",
      "At iterate    6    f=  1.92490D+01    |proj g|=  1.92077D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      6      8      6     0     0   1.921D-05   1.925D+01\n",
      "  F =   19.248972298702387     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "TrueRUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.27259D+01    |proj g|=  0.00000D+00\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      0      1      0     0     0   0.000D+00   2.273D+01\n",
      "  F =   22.725894756182566     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "\n",
      "[1.09384486 2.50221992]\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.06705D+01    |proj g|=  7.89983D-01\n",
      "\n",
      "At iterate    1    f=  2.00135D+01    |proj g|=  7.58822D-01\n",
      "\n",
      "At iterate    2    f=  1.97765D+01    |proj g|=  5.49673D-01\n",
      "\n",
      "At iterate    3    f=  1.96194D+01    |proj g|=  6.76802D-01\n",
      "\n",
      "At iterate    4    f=  1.93990D+01    |proj g|=  6.82257D-01\n",
      "\n",
      "At iterate    5    f=  1.92704D+01    |proj g|=  3.80406D-01\n",
      "\n",
      "At iterate    6    f=  1.92534D+01    |proj g|=  1.06940D-01\n",
      "\n",
      "At iterate    7    f=  1.92492D+01    |proj g|=  3.99358D-02\n",
      "\n",
      "At iterate    8    f=  1.92490D+01    |proj g|=  9.72839D-03\n",
      "\n",
      "TrueAt iterate    9    f=  1.92490D+01    |proj g|=  1.99489D-04\n",
      "\n",
      "At iterate   10    f=  1.92490D+01    |proj g|=  1.06781D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     10     14     10     0     0   1.068D-05   1.925D+01\n",
      "  F =   19.248972298686372     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "\n",
      "[  1.02123676 180.18970185]\n",
      "True\n",
      "[ 8.06863205 25.27995516]\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.29677D+01    |proj g|=  2.87101D-01\n",
      "\n",
      "At iterate    1    f=  2.28996D+01    |proj g|=  1.94700D-01\n",
      "\n",
      "At iterate    2    f=  2.28168D+01    |proj g|=  9.35790D-02\n",
      "\n",
      "At iterate    3    f=  2.27777D+01    |proj g|=  5.08562D-02\n",
      "\n",
      "At iterate    4    f=  2.27532D+01    |proj g|=  2.58837D-02\n",
      "\n",
      "At iterate    5    f=  2.27401D+01    |proj g|=  1.32821D-02\n",
      "\n",
      "At iterate    6    f=  2.27332D+01    |proj g|=  6.69975D-03\n",
      "\n",
      "At iterate    7    f=  2.27296D+01    |proj g|=  3.37144D-03\n",
      "\n",
      "At iterate    8    f=  2.27277D+01    |proj g|=  1.68947D-03\n",
      "\n",
      "At iterate    9    f=  2.27268D+01    |proj g|=  8.45764D-04\n",
      "\n",
      "At iterate   10    f=  2.27264D+01    |proj g|=  4.23017D-04\n",
      "\n",
      "At iterate   11    f=  2.27261D+01    |proj g|=  2.11515D-04\n",
      "\n",
      "At iterate   12    f=  2.27260D+01    |proj g|=  1.05734D-04\n",
      "\n",
      "At iterate   13    f=  2.27260D+01    |proj g|=  5.28436D-05\n",
      "\n",
      "At iterate   14    f=  2.27259D+01    |proj g|=  2.63996D-05\n",
      "\n",
      "At iterate   15    f=  2.27259D+01    |proj g|=  1.31791D-05\n",
      "\n",
      "At iterate   16    f=  2.27259D+01    |proj g|=  6.56966D-06\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     16     17     16     0     0   6.570D-06   2.273D+01\n",
      "  F =   22.725900035670154     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.26711D+01    |proj g|=  4.00346D-03\n",
      "\n",
      "At iterate    1    f=  2.26711D+01    |proj g|=  4.00565D-03\n",
      "  ys=-1.168E-08  -gs= 2.481E-05 BFGS update SKIPPED\n",
      "\n",
      "At iterate    2    f=  2.26319D+01    |proj g|=  9.89921D-03\n",
      "\n",
      "At iterate    3    f=  2.17730D+01    |proj g|=  3.75447D+00\n",
      "  ys=-1.838E-01  -gs= 1.398E-01 BFGS update SKIPPED\n",
      "\n",
      "At iterate    4    f=  2.11166D+01    |proj g|=  4.38944D-01\n",
      "\n",
      "At iterate    5    f=  1.92528D+01    |proj g|=  1.75839D-01\n",
      "\n",
      "At iterate    6    f=  1.92514D+01    |proj g|=  1.42913D-01\n",
      "\n",
      "At iterate    7    f=  1.92506D+01    |proj g|=  1.05342D-01\n",
      "\n",
      "At iterate    8    f=  1.92490D+01    |proj g|=  8.21314D-03\n",
      "\n",
      "At iterate    9    f=  1.92490D+01    |proj g|=  2.28405D-04\n",
      "True\n",
      "[1.00643208e+05 1.06250054e+00]\n",
      "\n",
      "At iterate   10    f=  1.92490D+01    |proj g|=  7.61401D-06\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     10     34     12     2     0   7.614D-06   1.925D+01\n",
      "  F =   19.248972298686486     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "True\n",
      "[1.00895692 1.66704307]\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.27259D+01    |proj g|=  1.17649D-99\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      0      1      0     0     0   1.176D-99   2.273D+01\n",
      "  F =   22.725894756182566     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "True\n",
      "[1.0054631  3.58007236]\n",
      "True\n",
      "[386.80603232   1.16231922]\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.99613D+01    |proj g|=  1.00167D+00\n",
      "\n",
      "At iterate    1    f=  1.95268D+01    |proj g|=  7.46543D-01\n",
      "\n",
      "At iterate    2    f=  1.93530D+01    |proj g|=  4.80559D-01\n",
      "\n",
      "At iterate    3    f=  1.92894D+01    |proj g|=  4.26453D-01\n",
      "\n",
      "At iterate    4    f=  1.92519D+01    |proj g|=  1.23658D-01\n",
      "\n",
      "At iterate    5    f=  1.92492D+01    |proj g|=  4.09309D-02\n",
      "\n",
      "At iterate    6    f=  1.92490D+01    |proj g|=  3.81623D-03\n",
      "\n",
      "At iterate    7    f=  1.92490D+01    |proj g|=  1.24127D-03\n",
      "\n",
      "At iterate    8    f=  1.92490D+01    |proj g|=  5.51902D-05\n",
      "\n",
      "At iterate    9    f=  1.92490D+01    |proj g|=  1.48710D-06\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      9     13      9     0     0   1.487D-06   1.925D+01\n",
      "  F =   19.248972298662309     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.14448D+01    |proj g|=  8.94852D-01\n",
      "\n",
      "At iterate    1    f=  2.09685D+01    |proj g|=  5.46385D-01\n",
      "\n",
      "At iterate    2    f=  2.00584D+01    |proj g|=  6.45860D-01\n",
      "\n",
      "At iterate    3    f=  1.98316D+01    |proj g|=  5.57782D-01\n",
      "\n",
      "At iterate    4    f=  1.94218D+01    |proj g|=  5.92018D-01\n",
      "\n",
      "At iterate    5    f=  1.92713D+01    |proj g|=  4.28726D-01\n",
      "\n",
      "At iterate    6    f=  1.92546D+01    |proj g|=  1.86227D-01\n",
      "\n",
      "At iterate    7    f=  1.92490D+01    |proj g|=  1.37847D-02\n",
      "\n",
      "At iterate    8    f=  1.92490D+01    |proj g|=  2.76037D-03\n",
      "\n",
      "At iterate    9    f=  1.92490D+01    |proj g|=  1.45495D-05\n",
      "\n",
      "At iterate   10    f=  1.92490D+01    |proj g|=  2.94320D-07\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2     10     18     10     0     0   2.943D-07   1.925D+01\n",
      "  F =   19.248972298661968     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.27241D+01    |proj g|=  5.62183D-03\n",
      "\n",
      "At iterate    1    f=  2.27241D+01    |proj g|=  5.72479D-03\n",
      "  ys=-5.788E-07  -gs= 3.160E-05 BFGS update SKIPPED\n",
      "\n",
      "At iterate    2    f=  2.25856D+01    |proj g|=  5.47438D-04\n",
      "  ys=-8.576E-01  -gs= 6.616E-03 BFGS update SKIPPED\n",
      "\n",
      "At iterate    3    f=  2.19897D+01    |proj g|=  1.10064D-03\n",
      "True\n",
      "At iterate    4    f=  2.19886D+01    |proj g|=  8.18582D-05\n",
      "\n",
      "At iterate    5    f=  2.19886D+01    |proj g|=  7.97150D-06\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      5     30      5     2     1   7.971D-06   2.199D+01\n",
      "  F =   21.988620504179927     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "\n",
      "[56115.50263298   532.94145593]\n",
      "True\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.27259D+01    |proj g|=  0.00000D+00\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      0      1      0     0     0   0.000D+00   2.273D+01\n",
      "  F =   22.725894756182566     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.90287D+01    |proj g|=  2.04788D-01\n",
      "\n",
      "At iterate    1    f=  1.90223D+01    |proj g|=  3.04450D-02\n",
      "\n",
      "At iterate    2    f=  1.90220D+01    |proj g|=  1.81604D-02\n",
      "\n",
      "At iterate    3    f=  1.90220D+01    |proj g|=  3.49027D-04\n",
      "True\n",
      "At iterate    4    f=  1.90220D+01    |proj g|=  3.71292D-06\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      4      6      4     0     0   3.713D-06   1.902D+01\n",
      "  F =   19.021963469841808     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "\n",
      "True\n",
      "True\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.85945D+01    |proj g|=  2.27090D-01\n",
      "\n",
      "At iterate    1    f=  1.85884D+01    |proj g|=  2.91967D-02\n",
      "\n",
      "At iterate    2    f=  1.85882D+01    |proj g|=  1.84445D-02\n",
      "\n",
      "At iterate    3    f=  1.85881D+01    |proj g|=  3.00069D-04\n",
      "\n",
      "At iterate    4    f=  1.85881D+01    |proj g|=  1.96792D-06\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      4      6      4     0     0   1.968D-06   1.859D+01\n",
      "  F =   18.588133079278755     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.77684D+01    |proj g|=  1.44205D-01\n",
      "\n",
      "At iterate    1    f=  1.77662D+01    |proj g|=  5.19499D-02\n",
      "\n",
      "At iterate    2    f=  1.77659D+01    |proj g|=  4.20353D-03\n",
      "\n",
      "At iterate    3    f=  1.77659D+01    |proj g|=  1.26553D-04\n",
      "\n",
      "At iterate    4    f=  1.77659D+01    |proj g|=  3.34310D-06\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      4      6      4     0     0   3.343D-06   1.777D+01\n",
      "  F =   17.765934323547512     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.80986D+01    |proj g|=  1.98923D-01\n",
      "\n",
      "At iterate    1    f=  1.80950D+01    |proj g|=  2.13310D-02\n",
      "\n",
      "At iterate    2    f=  1.80949D+01    |proj g|=  1.07584D-02\n",
      "\n",
      "At iterate    3    f=  1.80949D+01    |proj g|=  5.41339D-04\n",
      "True\n",
      "\n",
      "At iterate    4    f=  1.80949D+01    |proj g|=  3.68643D-06\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      4      6      4     0     0   3.686D-06   1.809D+01\n",
      "  F =   18.094918838740899     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.71019D+01    |proj g|=  2.19087D-01\n",
      "\n",
      "At iterate    1    f=  1.70985D+01    |proj g|=  5.42347D-02\n",
      "\n",
      "At iterate    2    f=  1.70981D+01    |proj g|=  2.44655D-02\n",
      "\n",
      "At iterate    3    f=  1.70980D+01    |proj g|=  9.17032D-04\n",
      "\n",
      "At iterate    4    f=  1.70980D+01    |proj g|=  1.48999D-05\n",
      "True\n",
      "\n",
      "At iterate    5    f=  1.70980D+01    |proj g|=  8.25709D-08\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      5      7      5     0     0   8.257D-08   1.710D+01\n",
      "  F =   17.098026690771025     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "True\n",
      "True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.66558D+01    |proj g|=  1.60368D-01\n",
      "\n",
      "At iterate    1    f=  1.66540D+01    |proj g|=  5.60060D-02\n",
      "\n",
      "At iterate    2    f=  1.66537D+01    |proj g|=  6.43750D-03\n",
      "\n",
      "At iterate    3    f=  1.66537D+01    |proj g|=  1.67008D-04\n",
      "\n",
      "At iterate    4    f=  1.66537D+01    |proj g|=  3.59276D-06\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      4      6      4     0     0   3.593D-06   1.665D+01\n",
      "  F =   16.653695317585985     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.53848D+01    |proj g|=  1.13582D-01\n",
      "\n",
      "At iterate    1    f=  1.53834D+01    |proj g|=  3.11696D-02\n",
      "\n",
      "At iterate    2    f=  1.53833D+01    |proj g|=  1.95283D-02\n",
      "\n",
      "At iterate    3    f=  1.53833D+01    |proj g|=  1.26162D-04\n",
      "\n",
      "At iterate    4    f=  1.53833D+01    |proj g|=  1.44089D-06\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      4      6      4     0     0   1.441D-06   1.538D+01\n",
      "  F =   15.383323843636255     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.50572D+01    |proj g|=  4.85984D-01\n",
      "\n",
      "At iterate    1    f=  1.50456D+01    |proj g|=  2.53916D-01\n",
      "\n",
      "At iterate    2    f=  1.50410D+01    |proj g|=  2.45588D-02\n",
      "\n",
      "At iterate    3    f=  1.50409D+01    |proj g|=  1.00702D-02\n",
      "\n",
      "At iterate    4    f=  1.50409D+01    |proj g|=  9.00504D-05\n",
      "True\n",
      "At iterate    5    f=  1.50409D+01    |proj g|=  1.05623D-06\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      5      7      5     0     0   1.056D-06   1.504D+01\n",
      "  F =   15.040897261631486     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.45316D+01    |proj g|=  4.90625D-01\n",
      "True\n",
      "True\n",
      "\n",
      "At iterate    1    f=  1.45209D+01    |proj g|=  1.11386D-01\n",
      "\n",
      "At iterate    2    f=  1.45201D+01    |proj g|=  4.92172D-02\n",
      "\n",
      "At iterate    3    f=  1.45200D+01    |proj g|=  2.08623D-03\n",
      "\n",
      "At iterate    4    f=  1.45200D+01    |proj g|=  1.28441D-04\n",
      "\n",
      "At iterate    5    f=  1.45200D+01    |proj g|=  4.79744D-06\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      5      8      5     0     0   4.797D-06   1.452D+01\n",
      "  F =   14.519952028913231     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.40628D+01    |proj g|=  1.32561D-01\n",
      "\n",
      "At iterate    1    f=  1.40610D+01    |proj g|=  4.50514D-02\n",
      "\n",
      "At iterate    2    f=  1.40609D+01    |proj g|=  2.51074D-02\n",
      "\n",
      "At iterate    3    f=  1.40609D+01    |proj g|=  1.64489D-04\n",
      "\n",
      "At iterate    4    f=  1.40609D+01    |proj g|=  6.84849D-07\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      4      6      4     0     0   6.848D-07   1.406D+01\n",
      "  F =   14.060877136154193     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.40025D+01    |proj g|=  5.33590D-01\n",
      "\n",
      "At iterate    1    f=  1.39931D+01    |proj g|=  6.20128D-02\n",
      "\n",
      "At iterate    2    f=  1.39927D+01    |proj g|=  3.92744D-02\n",
      "\n",
      "At iterate    3    f=  1.39927D+01    |proj g|=  9.53192D-04\n",
      "True\n",
      "\n",
      "At iterate    4    f=  1.39927D+01    |proj g|=  1.66548D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      4      7      4     0     0   1.665D-05   1.399D+01\n",
      "  F =   13.992654160053860     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.35044D+01    |proj g|=  3.17361D-01\n",
      "\n",
      "True\n",
      "True\n",
      "At iterate    1    f=  1.35018D+01    |proj g|=  1.72260D-01\n",
      "\n",
      "At iterate    2    f=  1.35008D+01    |proj g|=  4.15400D-02\n",
      "\n",
      "At iterate    3    f=  1.35007D+01    |proj g|=  1.24967D-02\n",
      "\n",
      "At iterate    4    f=  1.35007D+01    |proj g|=  2.71798D-04\n",
      "\n",
      "At iterate    5    f=  1.35007D+01    |proj g|=  3.58598D-06\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      5      7      5     0     0   3.586D-06   1.350D+01\n",
      "  F =   13.500669814113607     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.28530D+01    |proj g|=  4.35354D-01\n",
      "\n",
      "At iterate    1    f=  1.28483D+01    |proj g|=  6.69180D-02\n",
      "\n",
      "At iterate    2    f=  1.28481D+01    |proj g|=  4.00575D-02\n",
      "\n",
      "At iterate    3    f=  1.28480D+01    |proj g|=  9.25390D-04\n",
      "\n",
      "At iterate    4    f=  1.28480D+01    |proj g|=  1.83081D-05\n",
      "\n",
      "At iterate    5    f=  1.28480D+01    |proj g|=  1.01109D-07\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      5      8      5     0     0   1.011D-07   1.285D+01\n",
      "  F =   12.847991370091535     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.22205D+01    |proj g|=  4.06830D-01\n",
      "\n",
      "At iterate    1    f=  1.22168D+01    |proj g|=  8.88362D-02\n",
      "\n",
      "At iterate    2    f=  1.22165D+01    |proj g|=  5.00258D-02\n",
      "\n",
      "At iterate    3    f=  1.22164D+01    |proj g|=  1.37485D-03\n",
      "\n",
      "At iterate    4    f=  1.22164D+01    |proj g|=  4.74147D-05\n",
      "True\n",
      "\n",
      "At iterate    5    f=  1.22164D+01    |proj g|=  1.57964D-07\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      5      8      5     0     0   1.580D-07   1.222D+01\n",
      "  F =   12.216374024230504     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.21030D+01    |proj g|=  2.29016D-01\n",
      "True\n",
      "True\n",
      "At iterate    1    f=  1.20992D+01    |proj g|=  1.03442D-01\n",
      "\n",
      "At iterate    2    f=  1.20988D+01    |proj g|=  4.38684D-02\n",
      "\n",
      "At iterate    3    f=  1.20987D+01    |proj g|=  5.47657D-04\n",
      "\n",
      "At iterate    4    f=  1.20987D+01    |proj g|=  2.22194D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      4      6      4     0     0   2.222D-05   1.210D+01\n",
      "  F =   12.098707811958406     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iter\n",
      "ate    0    f=  1.14990D+01    |proj g|=  3.06885D-01\n",
      "\n",
      "At iterate    1    f=  1.14969D+01    |proj g|=  1.07963D-01\n",
      "\n",
      "At iterate    2    f=  1.14966D+01    |proj g|=  4.74693D-02\n",
      "\n",
      "At iterate    3    f=  1.14965D+01    |proj g|=  7.96346D-04\n",
      "\n",
      "At iterate    4    f=  1.14965D+01    |proj g|=  5.89079D-06\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      4      7      4     0     0   5.891D-06   1.150D+01\n",
      "  F =   11.496482079955975     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.04476D+01    |proj g|=  1.71341D-01\n",
      "\n",
      "At iterate    1    f=  1.04460D+01    |proj g|=  4.64026D-02\n",
      "\n",
      "At iterate    2    f=  1.04459D+01    |proj g|=  7.33304D-03\n",
      "\n",
      "At iterate    3    f=  1.04459D+01    |proj g|=  1.54656D-04\n",
      "True\n",
      "\n",
      "At iterate    4    f=  1.04459D+01    |proj g|=  1.50219D-07\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      4      7      4     0     0   1.502D-07   1.045D+01\n",
      "  F =   10.445941434338259     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "True\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.47399D+00    |proj g|=  3.26151D-01\n",
      "\n",
      "At iterate    1    f=  9.47226D+00    |proj g|=  7.27598D-02\n",
      "\n",
      "At iterate    2    f=  9.47213D+00    |proj g|=  4.04599D-02\n",
      "\n",
      "At iterate    3    f=  9.47208D+00    |proj g|=  5.74490D-04\n",
      "\n",
      "At iterate    4    f=  9.47208D+00    |proj g|=  1.41524D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      4      7      4     0     0   1.415D-05   9.472D+00\n",
      "  F =   9.4720781790433719     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  8.41118D+00    |proj g|=  4.41300D-01\n",
      "\n",
      "At iterate    1    f=  8.40765D+00    |proj g|=  6.77669D-02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate    2    f=  8.40749D+00    |proj g|=  4.54100D-02\n",
      "\n",
      "At iterate    3    f=  8.40743D+00    |proj g|=  2.55623D-03\n",
      "\n",
      "At iterate    4    f=  8.40743D+00    |proj g|=  4.31243D-05\n",
      "True\n",
      "\n",
      "At iterate    5    f=  8.40743D+00    |proj g|=  1.22633D-07\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      5      8      6     0     0   1.226D-07   8.407D+00\n",
      "  F =   8.4074268607620581     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  7.60374D+00    |proj g|=  1.88015D-01\n",
      "\n",
      "At iterate    1    f=  7.60199D+00    |proj g|=  8.97015D-02\n",
      "\n",
      "At iterate    2    f=  7.60178D+00    |proj g|=  3.05345D-02\n",
      "\n",
      "At iterate    3    f=  7.60175D+00    |proj g|=  2.51661D-04\n",
      "True\n",
      "\n",
      "At iterate    4    f=  7.60175D+00    |proj g|=  5.10454D-06\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      4      6      4     0     0   5.105D-06   7.602D+00\n",
      "  F =   7.6017465998104043     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "True\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  6.69756D+00    |proj g|=  2.74330D-01\n",
      "\n",
      "At iterate    1    f=  6.69597D+00    |proj g|=  1.23965D-01\n",
      "\n",
      "At iterate    2    f=  6.69562D+00    |proj g|=  3.83041D-02\n",
      "\n",
      "At iterate    3    f=  6.69558D+00    |proj g|=  5.19382D-04\n",
      "\n",
      "At iterate    4    f=  6.69558D+00    |proj g|=  2.25210D-06\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      4      7      4     0     0   2.252D-06   6.696D+00\n",
      "  F =   6.6955813562230020     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  6.60799D+00    |proj g|=  2.70279D-01\n",
      "\n",
      "At iterate    1    f=  6.60628D+00    |proj g|=  1.31948D-01\n",
      "\n",
      "At iterate    2    f=  6.60589D+00    |proj g|=  2.79729D-02\n",
      "\n",
      "At iterate    3    f=  6.60587D+00    |proj g|=  3.65637D-04\n",
      "True\n",
      "\n",
      "At iterate    4    f=  6.60587D+00    |proj g|=  2.97070D-06\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      4      7      4     0     0   2.971D-06   6.606D+00\n",
      "  F =   6.6058727336416965     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  5.58739D+00    |proj g|=  4.00446D-01\n",
      "\n",
      "At iterate    1    f=  5.58564D+00    |proj g|=  7.71678D-02\n",
      "True\n",
      "\n",
      "At iterate    2    f=  5.58552D+00    |proj g|=  4.88129D-02\n",
      "\n",
      "At iterate    3    f=  5.58546D+00    |proj g|=  4.54043D-04\n",
      "\n",
      "At iterate    4    f=  5.58546D+00    |proj g|=  2.55919D-06\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      4      7      5     0     0   2.559D-06   5.585D+00\n",
      "  F =   5.5854623562974126     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  4.91685D+00    |proj g|=  2.50166D-01\n",
      "\n",
      "At iterate    1    f=  4.91524D+00    |proj g|=  5.13916D-02\n",
      "\n",
      "At iterate    2    f=  4.91522D+00    |proj g|=  5.49782D-03\n",
      "\n",
      "At iterate    3    f=  4.91521D+00    |proj g|=  1.50738D-04\n",
      "True\n",
      "\n",
      "At iterate    4    f=  4.91521D+00    |proj g|=  8.28589D-08\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      4      7      4     0     0   8.286D-08   4.915D+00\n",
      "  F =   4.9152146525028684     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  4.85059D+00    |proj g|=  2.20224D-01\n",
      "\n",
      "At iterate    1    f=  4.84896D+00    |proj g|=  1.10955D-01\n",
      "\n",
      "At iterate    2    f=  4.84883D+00    |proj g|=  5.38711D-02\n",
      "\n",
      "At iterate    3    f=  4.84877D+00    |proj g|=  2.91680D-04\n",
      "True\n",
      "\n",
      "At iterate    4    f=  4.84877D+00    |proj g|=  9.41880D-06\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      4      6      4     0     0   9.419D-06   4.849D+00\n",
      "  F =   4.8487723683118134     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "True\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  3.81266D+00    |proj g|=  3.81390D-01\n",
      "\n",
      "At iterate    1    f=  3.80937D+00    |proj g|=  7.10847D-02\n",
      "\n",
      "At iterate    2    f=  3.80925D+00    |proj g|=  5.28387D-02\n",
      "\n",
      "At iterate    3    f=  3.80919D+00    |proj g|=  5.70074D-03\n",
      "\n",
      "At iterate    4    f=  3.80918D+00    |proj g|=  6.16577D-05\n",
      "\n",
      "At iterate    5    f=  3.80918D+00    |proj g|=  3.70190D-07\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      5      8      6     0     0   3.702D-07   3.809D+00\n",
      "  F =   3.8091846219286083     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.69421D+00    |proj g|=  2.26845D-01\n",
      "\n",
      "At iterate    1    f=  2.69321D+00    |proj g|=  1.16486D-01\n",
      "\n",
      "At iterate    2    f=  2.69297D+00    |proj g|=  2.09370D-02\n",
      "\n",
      "At iterate    3    f=  2.69296D+00    |proj g|=  1.91808D-04\n",
      "True\n",
      "\n",
      "At iterate    4    f=  2.69296D+00    |proj g|=  1.65993D-06\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      4      7      4     0     0   1.660D-06   2.693D+00\n",
      "  F =   2.6929598008594198     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.78453D+00    |proj g|=  3.64700D-01\n",
      "True\n",
      "\n",
      "At iterate    1    f=  1.78161D+00    |proj g|=  4.38649D-02\n",
      "\n",
      "At iterate    2    f=  1.78160D+00    |proj g|=  1.14752D-02\n",
      "\n",
      "At iterate    3    f=  1.78159D+00    |proj g|=  6.84628D-03\n",
      "\n",
      "At iterate    4    f=  1.78159D+00    |proj g|=  3.02740D-04\n",
      "\n",
      "At iterate    5    f=  1.78159D+00    |proj g|=  1.42972D-06\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      5      8      6     0     0   1.430D-06   1.782D+00\n",
      "  F =   1.7815934394192396     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  7.15295D-01    |proj g|=  1.85980D-01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate    1    f=  7.14358D-01    |proj g|=  1.55566D-01\n",
      "\n",
      "At iterate    2    f=  7.14130D-01    |proj g|=  1.30412D-02\n",
      "\n",
      "At iterate    3    f=  7.14127D-01    |proj g|=  1.82988D-05\n",
      "True\n",
      "\n",
      "At iterate    4    f=  7.14127D-01    |proj g|=  1.71693D-07\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      4      6      4     0     0   1.717D-07   7.141D-01\n",
      "  F =  0.71412727404246823     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f= -4.85835D-01    |proj g|=  2.12523D-01\n",
      "\n",
      "At iterate    1    f= -4.86882D-01    |proj g|=  6.55657D-02\n",
      "\n",
      "At iterate    2    f= -4.86944D-01    |proj g|=  6.99688D-03\n",
      "\n",
      "At iterate    3    f= -4.86945D-01    |proj g|=  8.77067D-05\n",
      "True\n",
      "\n",
      "At iterate    4    f= -4.86945D-01    |proj g|=  5.43325D-08\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      4      7      4     0     0   5.433D-08  -4.869D-01\n",
      "  F = -0.48694472556026369     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "learning_function= ExpectedImprovement()\n",
    "a = AdaptiveKriging(runmodel_object=rmodel, samples=x.samples, surrogate=K,\n",
    "                    learning_nsamples=10 ** 3, n_add=1,\n",
    "                    learning_function=learning_function, distributions=marginals)\n",
    "a.run(nsamples=50)\n",
    "elapsed_time = time.time() - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize initial and new samples on top of the Branin-Hoo surface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x18a26be20>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num = 200\n",
    "xlist = np.linspace(-6, 11, num)\n",
    "ylist = np.linspace(-1, 16, num)\n",
    "X, Y = np.meshgrid(xlist, ylist)\n",
    "\n",
    "Z = np.zeros((num, num))\n",
    "for i in range(num):\n",
    "    for j in range(num):\n",
    "        tem = np.array([[X[i, j], Y[i, j]]])\n",
    "        Z[i, j] = function(tem)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "cp = ax.contourf(X, Y, Z, 10)\n",
    "xlabel('x1')\n",
    "ylabel('x2')\n",
    "fig.colorbar(cp)\n",
    "nd = x.nsamples\n",
    "scatter(a.samples[nd:, 0], a.samples[nd:, 1], color='pink', label='New samples')\n",
    "scatter(x.samples[:nd, 0], x.samples[:nd, 1], color='Red', label='Initial samples')\n",
    "title('Branin-Hoo function');\n",
    "legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
